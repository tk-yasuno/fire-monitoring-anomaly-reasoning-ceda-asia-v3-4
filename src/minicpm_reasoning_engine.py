#!/usr/bin/env python3
"""
MiniCPMæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ for Global Fire Monitoring and Anomaly Reasoning System v3.3
ç•°å¸¸ç«ç½ã‚°ãƒªãƒƒãƒ‰ã®æ¨è«–ã¨èª¬æ˜ç”Ÿæˆ
"""

import os
import json
import logging
from datetime import datetime
from pathlib import Path
import numpy as np
import pandas as pd

# MiniCPMãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰
try:
    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªimportã‚’ä½¿ç”¨
    # from transformers import AutoTokenizer, AutoModelForCausalLM
    # import torch
    MINICPM_AVAILABLE = False  # å®Ÿéš›ã®ç’°å¢ƒã§ã¯ True ã«è¨­å®š
except ImportError:
    MINICPM_AVAILABLE = False

class MiniCPMReasoningEngine:
    """
    MiniCPM-basedæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ for ç«ç½ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰åˆ†æ
    """
    
    def __init__(self, config_path=None):
        """
        åˆæœŸåŒ–
        
        Args:
            config_path (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.logger = logging.getLogger(__name__)
        self.config = self._load_config(config_path)
        
        # MiniCPMãƒ¢ãƒ‡ãƒ«é–¢é€£
        self.model = None
        self.tokenizer = None
        self.model_loaded = False
        
        # æ¨è«–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.reasoning_templates = self._initialize_templates()
        
        # æ¨è«–å±¥æ­´
        self.reasoning_history = []
        
        self.logger.info("ğŸ¤– MiniCPMæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def _load_config(self, config_path):
        """è¨­å®šèª­ã¿è¾¼ã¿"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {
                "model": "minicpm",
                "max_tokens": 512,
                "temperature": 0.7,
                "top_p": 0.9,
                "reasoning_depth": "detailed"
            }
    
    def _initialize_templates(self):
        """æ¨è«–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆæœŸåŒ–"""
        return {
            "system_prompt": """ã‚ãªãŸã¯è¡›æ˜Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸç«ç½ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®å°‚é–€åˆ†æè€…ã§ã™ã€‚
ç•°å¸¸ãªç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™ã‚°ãƒªãƒƒãƒ‰ã‚»ãƒ«ã«ã¤ã„ã¦ã€ç§‘å­¦çš„ã§å®Ÿç”¨çš„ãªåˆ†æã¨æ¨è«–ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€ç•°å¸¸ã®åŸå› ã€ãƒªã‚¹ã‚¯è©•ä¾¡ã€æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚""",
            
            "anomaly_analysis_prompt": """
ç«ç½ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰åˆ†æ:

ä½ç½®æƒ…å ±:
- ç·¯åº¦: {latitude:.3f}
- çµŒåº¦: {longitude:.3f}
- å¤§é™¸: {continent}

ç«ç½ãƒ‡ãƒ¼ã‚¿:
- ç«ç½æ´»å‹•å¼·åº¦: {fire_activity:.2f}
- ç„¼å¤±é¢ç©: {burned_area:.2f}
- ç•°å¸¸ã‚¹ã‚³ã‚¢: {anomaly_score:.3f}

è¿‘å‚ãƒ‡ãƒ¼ã‚¿:
- è¿‘å‚æœ€å¤§å€¤: {neighbor_max:.2f}
- è¿‘å‚æ¨™æº–åå·®: {neighbor_std:.2f}
- è¿‘å‚å¹³å‡: {neighbor_mean:.2f}

ç’°å¢ƒè¦å› :
- å¹³å‡æ°—æ¸©: {temperature:.1f}Â°C
- é™æ°´é‡: {precipitation:.1f}mm
- æ¤ç”ŸæŒ‡æ•°: {vegetation_index:.3f}
- æ¨™é«˜: {elevation:.0f}m

åˆ†æè¦æ±‚:
1. ã“ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸»è¦ãªåŸå› ã‚’ç‰¹å®šã—ã¦ãã ã•ã„
2. ç«ç½ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„
3. æ¨å¥¨ã•ã‚Œã‚‹ç›£è¦–ãƒ»å¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã—ã¦ãã ã•ã„
4. é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®äºˆæ¸¬å¯èƒ½æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„
""",
            
            "risk_assessment_prompt": """
ãƒªã‚¹ã‚¯è©•ä¾¡åˆ†æ:

ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ç‰¹æ€§:
{grid_characteristics}

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰åŒ…æ‹¬çš„ãªãƒªã‚¹ã‚¯è©•ä¾¡ã‚’è¡Œã£ã¦ãã ã•ã„:
1. ç«ç½æ‹¡æ•£ãƒªã‚¹ã‚¯ï¼ˆè¿‘å‚ã¸ã®å½±éŸ¿ï¼‰
2. ç’°å¢ƒãƒ»ç”Ÿæ…‹ç³»ã¸ã®å½±éŸ¿
3. äººé–“æ´»å‹•ã¸ã®è„…å¨ãƒ¬ãƒ™ãƒ«
4. çµŒæ¸ˆçš„å½±éŸ¿ã®å¯èƒ½æ€§
5. æ°—å€™å¤‰å‹•ã¨ã®é–¢é€£æ€§

å„ãƒªã‚¹ã‚¯ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ ¹æ‹ ã¨æ•°å€¤çš„ãªè©•ä¾¡ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
""",
            
            "mitigation_strategy_prompt": """
ç·©å’Œæˆ¦ç•¥ç«‹æ¡ˆ:

ç•°å¸¸ç«ç½ã‚°ãƒªãƒƒãƒ‰: {grid_summary}
ãƒªã‚¹ã‚¯è©•ä¾¡: {risk_assessment}

ä»¥ä¸‹ã®ç·©å’Œæˆ¦ç•¥ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„:
1. å³æ™‚å¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ24æ™‚é–“ä»¥å†…ï¼‰
2. çŸ­æœŸå¯¾ç­–ï¼ˆ1é€±é–“ä»¥å†…ï¼‰
3. ä¸­é•·æœŸæˆ¦ç•¥ï¼ˆ1ãƒ¶æœˆä»¥ä¸Šï¼‰
4. äºˆé˜²æªç½®ã®æ¨å¥¨
5. ç›£è¦–ä½“åˆ¶ã®å¼·åŒ–æ¡ˆ

å„æˆ¦ç•¥ã«ã¤ã„ã¦ã€å®Ÿæ–½ã®å„ªå…ˆåº¦ã€å¿…è¦ãƒªã‚½ãƒ¼ã‚¹ã€æœŸå¾…åŠ¹æœã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
"""
        }
    
    def load_model(self):
        """MiniCPMãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if MINICPM_AVAILABLE:
            try:
                # å®Ÿéš›ã®å®Ÿè£…ä¾‹
                # model_path = self.config.get("model_path", "openbmb/MiniCPM-Llama3-V-2_5")
                # self.tokenizer = AutoTokenizer.from_pretrained(model_path)
                # self.model = AutoModelForCausalLM.from_pretrained(
                #     model_path,
                #     torch_dtype=torch.float16,
                #     device_map="auto"
                # )
                self.model_loaded = True
                self.logger.info("âœ… MiniCPMãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ MiniCPMãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                self.model_loaded = False
        else:
            self.logger.warning("âš ï¸ MiniCPMæœªåˆ©ç”¨ - ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼æ¨è«–ã‚’ä½¿ç”¨")
            self.model_loaded = False
    
    def generate_anomaly_reasoning(self, grid_data, analysis_context=None):
        """
        ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ã®æ¨è«–ç”Ÿæˆ
        
        Args:
            grid_data (dict): ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿
            analysis_context (dict): è¿½åŠ åˆ†æã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            dict: æ¨è«–çµæœ
        """
        try:
            if self.model_loaded:
                return self._generate_with_minicpm(grid_data, analysis_context)
            else:
                return self._generate_with_template(grid_data, analysis_context)
        except Exception as e:
            self.logger.error(f"âŒ æ¨è«–ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_fallback_reasoning(grid_data)
    
    def _generate_with_minicpm(self, grid_data, analysis_context):
        """MiniCPMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«–ç”Ÿæˆ"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªå‡¦ç†ã‚’è¡Œã†
        """
        prompt = self._build_analysis_prompt(grid_data, analysis_context)
        
        inputs = self.tokenizer(prompt, return_tensors="pt")
        
        with torch.no_grad():
            outputs = self.model.generate(
                inputs.input_ids,
                max_length=self.config.get("max_tokens", 512),
                temperature=self.config.get("temperature", 0.7),
                top_p=self.config.get("top_p", 0.9),
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        """
        
        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
        reasoning = self._generate_with_template(grid_data, analysis_context)
        reasoning["model"] = "minicpm_actual"
        reasoning["confidence"] = 0.85
        
        return reasoning
    
    def _generate_with_template(self, grid_data, analysis_context):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹æ¨è«–ç”Ÿæˆ"""
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        location_info = {
            'latitude': grid_data.get('latitude', 0),
            'longitude': grid_data.get('longitude', 0),
            'continent': grid_data.get('continent', 'Unknown')
        }
        
        fire_metrics = {
            'fire_activity': grid_data.get('fire_activity', 0),
            'burned_area': grid_data.get('burned_area_total', 0),
            'anomaly_score': grid_data.get('anomaly_score', 0)
        }
        
        # æ¨è«–ã®ç”Ÿæˆ
        primary_analysis = self._analyze_primary_factors(grid_data)
        risk_assessment = self._assess_risk_level(grid_data, primary_analysis)
        recommendations = self._generate_recommendations(grid_data, risk_assessment)
        
        # ä¿¡é ¼åº¦è¨ˆç®—
        confidence = self._calculate_confidence(grid_data, primary_analysis)
        
        reasoning_result = {
            "explanation": self._build_comprehensive_explanation(
                location_info, fire_metrics, primary_analysis, risk_assessment
            ),
            "primary_factors": primary_analysis["factors"],
            "risk_assessment": risk_assessment,
            "recommendations": recommendations,
            "confidence": confidence,
            "model": "template_enhanced",
            "timestamp": datetime.now().isoformat(),
            "analysis_depth": "detailed"
        }
        
        # æ¨è«–å±¥æ­´ã«è¿½åŠ 
        self.reasoning_history.append(reasoning_result)
        
        return reasoning_result
    
    def _analyze_primary_factors(self, grid_data):
        """ä¸»è¦å› å­åˆ†æ"""
        factors = []
        severity_score = 0
        
        fire_activity = grid_data.get('fire_activity', 0)
        neighbor_max = grid_data.get('neighbor_max', 0)
        neighbor_std = grid_data.get('neighbor_std', 0)
        burned_area = grid_data.get('burned_area_total', 0)
        
        # ç«ç½æ´»å‹•å¼·åº¦åˆ†æ
        if fire_activity > 15:
            factors.append("æ¥µç«¯ã«é«˜ã„ç«ç½æ´»å‹•å¼·åº¦ï¼ˆè‡¨ç•Œãƒ¬ãƒ™ãƒ«ï¼‰")
            severity_score += 3
        elif fire_activity > 8:
            factors.append("é«˜ã„ç«ç½æ´»å‹•å¼·åº¦")
            severity_score += 2
        elif fire_activity > 3:
            factors.append("ä¸­ç¨‹åº¦ã®ç«ç½æ´»å‹•å¼·åº¦")
            severity_score += 1
        
        # è¿‘å‚ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        if neighbor_max > 20:
            factors.append("è¿‘å‚ã‚¨ãƒªã‚¢ã§ã®æ¥µç«¯ãªç«ç½é›†ä¸­")
            severity_score += 2
        elif neighbor_max > 10:
            factors.append("è¿‘å‚ã‚¨ãƒªã‚¢ã§ã®é«˜ç«ç½æ´»å‹•")
            severity_score += 1
        
        if neighbor_std > 8:
            factors.append("è¿‘å‚ç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é«˜ã„ä¸å‡ä¸€æ€§")
            severity_score += 1
        
        # ç„¼å¤±é¢ç©åˆ†æ
        if burned_area > fire_activity * 2:
            factors.append("ç«ç½å¼·åº¦ã«æ¯”ã—ã¦åºƒç¯„å›²ã®ç„¼å¤±")
            severity_score += 1
        
        # ç’°å¢ƒè¦å› 
        temperature = grid_data.get('temperature_avg', 25)
        precipitation = grid_data.get('precipitation_total', 50)
        
        if temperature > 35:
            factors.append("é«˜æ¸©ç’°å¢ƒã«ã‚ˆã‚‹ç«ç½ãƒªã‚¹ã‚¯å¢—å¤§")
            severity_score += 1
        
        if precipitation < 20:
            factors.append("å°‘é›¨ã«ã‚ˆã‚‹ä¹¾ç‡¥çŠ¶æ…‹")
            severity_score += 1
        
        return {
            "factors": factors,
            "severity_score": severity_score,
            "primary_driver": self._identify_primary_driver(grid_data)
        }
    
    def _identify_primary_driver(self, grid_data):
        """ä¸»è¦é§†å‹•è¦å› ã®ç‰¹å®š"""
        fire_activity = grid_data.get('fire_activity', 0)
        neighbor_max = grid_data.get('neighbor_max', 0)
        temperature = grid_data.get('temperature_avg', 25)
        precipitation = grid_data.get('precipitation_total', 50)
        
        # é§†å‹•è¦å› ã®é‡è¦åº¦è©•ä¾¡
        drivers = {
            "fire_intensity": fire_activity / 20,  # æ­£è¦åŒ–
            "spatial_clustering": neighbor_max / 25,
            "thermal_stress": max(0, (temperature - 30) / 20),
            "drought_conditions": max(0, (50 - precipitation) / 50)
        }
        
        primary_driver = max(drivers, key=drivers.get)
        
        driver_descriptions = {
            "fire_intensity": "å±€æ‰€çš„ãªé«˜å¼·åº¦ç«ç½",
            "spatial_clustering": "ç©ºé–“çš„ç«ç½ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°",
            "thermal_stress": "ç†±ã‚¹ãƒˆãƒ¬ã‚¹æ¡ä»¶",
            "drought_conditions": "å¹²ã°ã¤çŠ¶æ…‹"
        }
        
        return {
            "type": driver_descriptions[primary_driver],
            "strength": drivers[primary_driver],
            "confidence": min(0.9, drivers[primary_driver] + 0.3)
        }
    
    def _assess_risk_level(self, grid_data, primary_analysis):
        """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è©•ä¾¡"""
        severity_score = primary_analysis["severity_score"]
        
        if severity_score >= 6:
            risk_level = "critical"
            urgency = "immediate"
            spread_risk = "very_high"
        elif severity_score >= 4:
            risk_level = "high"
            urgency = "within_24h"
            spread_risk = "high"
        elif severity_score >= 2:
            risk_level = "moderate"
            urgency = "within_week"
            spread_risk = "moderate"
        else:
            risk_level = "low"
            urgency = "routine_monitoring"
            spread_risk = "low"
        
        # å¤§é™¸åˆ¥ãƒªã‚¹ã‚¯èª¿æ•´
        continent = grid_data.get('continent', 'Unknown')
        continent_risk_factors = {
            'Africa': 1.2,      # ã‚µãƒãƒ³ãƒŠç«ç½ã®é«˜ãƒªã‚¹ã‚¯
            'Asia': 1.1,        # äººå£å¯†åº¦ã«ã‚ˆã‚‹è¿½åŠ ãƒªã‚¹ã‚¯
            'North America': 1.0,
            'South America': 1.15,  # ã‚¢ãƒã‚¾ãƒ³ç­‰ã®ç”Ÿæ…‹ç³»ãƒªã‚¹ã‚¯
            'Europe': 0.9,
            'Oceania': 1.1
        }
        
        risk_multiplier = continent_risk_factors.get(continent, 1.0)
        
        return {
            "level": risk_level,
            "urgency": urgency,
            "spread_risk": spread_risk,
            "severity_score": severity_score,
            "risk_multiplier": risk_multiplier,
            "adjusted_risk": min(10, severity_score * risk_multiplier),
            "ecosystem_threat": self._assess_ecosystem_threat(grid_data),
            "human_impact": self._assess_human_impact(grid_data)
        }
    
    def _assess_ecosystem_threat(self, grid_data):
        """ç”Ÿæ…‹ç³»è„…å¨è©•ä¾¡"""
        vegetation_index = grid_data.get('vegetation_index', 0.5)
        fire_activity = grid_data.get('fire_activity', 0)
        
        if vegetation_index > 0.7 and fire_activity > 10:
            return "high_biodiversity_loss_risk"
        elif vegetation_index > 0.5 and fire_activity > 5:
            return "moderate_ecosystem_impact"
        else:
            return "low_ecosystem_threat"
    
    def _assess_human_impact(self, grid_data):
        """äººé–“æ´»å‹•ã¸ã®å½±éŸ¿è©•ä¾¡"""
        population_density = grid_data.get('population_density', 1)
        distance_to_water = grid_data.get('distance_to_water', 50)
        
        if population_density > 100 or distance_to_water < 5:
            return "high_human_impact_risk"
        elif population_density > 10 or distance_to_water < 20:
            return "moderate_human_impact"
        else:
            return "low_human_impact"
    
    def _generate_recommendations(self, grid_data, risk_assessment):
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        recommendations = {
            "immediate_actions": [],
            "short_term_measures": [],
            "long_term_strategies": [],
            "monitoring_enhancements": []
        }
        
        risk_level = risk_assessment["level"]
        continent = grid_data.get('continent', 'Unknown')
        
        # å³æ™‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if risk_level == "critical":
            recommendations["immediate_actions"].extend([
                "ç¾åœ°ç·Šæ€¥ãƒãƒ¼ãƒ ã®æ´¾é£",
                "è¡›æ˜Ÿç›£è¦–é »åº¦ã®å¢—åŠ ï¼ˆ1æ—¥3å›â†’6å›ï¼‰",
                "è¿‘éš£ä½æ°‘ã¸ã®è­¦å ±ç™ºå‡º",
                "æ¶ˆé˜²ãƒªã‚½ãƒ¼ã‚¹ã®äº‹å‰é…ç½®"
            ])
        elif risk_level == "high":
            recommendations["immediate_actions"].extend([
                "ç¾åœ°èª¿æŸ»ãƒãƒ¼ãƒ ã®æ´¾é£æº–å‚™",
                "ç›£è¦–é »åº¦ã®å¢—åŠ ",
                "é–¢ä¿‚æ©Ÿé–¢ã¸ã®æƒ…å ±å…±æœ‰"
            ])
        
        # çŸ­æœŸå¯¾ç­–
        if risk_level in ["critical", "high"]:
            recommendations["short_term_measures"].extend([
                "ç«ç½å¢ƒç•Œã®ç²¾å¯†ãƒãƒƒãƒ”ãƒ³ã‚°",
                "æ°—è±¡æ¡ä»¶ã®è©³ç´°ç›£è¦–",
                "é¿é›£è¨ˆç”»ã®ç¢ºèªãƒ»æ›´æ–°"
            ])
        
        # é•·æœŸæˆ¦ç•¥
        recommendations["long_term_strategies"].extend([
            "ç«ç½ãƒªã‚¹ã‚¯ãƒãƒƒãƒ—ã®æ›´æ–°",
            "æ¤ç”Ÿç®¡ç†è¨ˆç”»ã®è¦‹ç›´ã—",
            "æ—©æœŸè­¦æˆ’ã‚·ã‚¹ãƒ†ãƒ ã®æ”¹å–„"
        ])
        
        # ç›£è¦–å¼·åŒ–
        recommendations["monitoring_enhancements"].extend([
            "é«˜è§£åƒåº¦è¡›æ˜Ÿãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨",
            "åœ°ä¸Šã‚»ãƒ³ã‚µãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ‹¡å……",
            "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦å‘ä¸Š"
        ])
        
        return recommendations
    
    def _calculate_confidence(self, grid_data, primary_analysis):
        """ä¿¡é ¼åº¦è¨ˆç®—"""
        base_confidence = 0.6
        
        # ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ã«ã‚ˆã‚‹èª¿æ•´
        available_features = sum(1 for key in ['fire_activity', 'neighbor_max', 'temperature_avg'] 
                               if grid_data.get(key) is not None)
        completeness_bonus = (available_features / 3) * 0.2
        
        # åˆ†æè¦å› æ•°ã«ã‚ˆã‚‹èª¿æ•´
        factor_bonus = min(0.15, len(primary_analysis["factors"]) * 0.03)
        
        # ä¸»è¦é§†å‹•è¦å› ã®ç¢ºå®Ÿæ€§ã«ã‚ˆã‚‹èª¿æ•´
        driver_confidence = primary_analysis["primary_driver"]["confidence"] * 0.1
        
        final_confidence = min(0.95, base_confidence + completeness_bonus + factor_bonus + driver_confidence)
        
        return round(final_confidence, 3)
    
    def _build_comprehensive_explanation(self, location_info, fire_metrics, primary_analysis, risk_assessment):
        """åŒ…æ‹¬çš„èª¬æ˜æ–‡ã®æ§‹ç¯‰"""
        continent = location_info['continent']
        lat, lon = location_info['latitude'], location_info['longitude']
        fire_activity = fire_metrics['fire_activity']
        anomaly_score = fire_metrics['anomaly_score']
        
        # åŸºæœ¬çŠ¶æ³
        explanation = f"""
{continent}ã®åº§æ¨™({lat:.3f}, {lon:.3f})ã«ãŠã„ã¦ç•°å¸¸ãªç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚

ã€ç•°å¸¸ã®ç‰¹å¾´ã€‘
ç«ç½æ´»å‹•å¼·åº¦: {fire_activity:.2f} (ç•°å¸¸ã‚¹ã‚³ã‚¢: {anomaly_score:.3f})
ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {risk_assessment['level'].upper()}
"""
        
        # ä¸»è¦å› å­
        if primary_analysis["factors"]:
            explanation += f"""
ã€ä¸»è¦å› å­ã€‘
{chr(10).join(f"â€¢ {factor}" for factor in primary_analysis["factors"])}
"""
        
        # é§†å‹•è¦å› 
        primary_driver = primary_analysis["primary_driver"]
        explanation += f"""
ã€ä¸»è¦é§†å‹•è¦å› ã€‘
{primary_driver['type']} (ç¢ºåº¦: {primary_driver['confidence']:.1%})
"""
        
        # ãƒªã‚¹ã‚¯è©•ä¾¡
        explanation += f"""
ã€ãƒªã‚¹ã‚¯è©•ä¾¡ã€‘
â€¢ ç·Šæ€¥åº¦: {risk_assessment['urgency']}
â€¢ æ‹¡æ•£ãƒªã‚¹ã‚¯: {risk_assessment['spread_risk']}
â€¢ ç·åˆã‚¹ã‚³ã‚¢: {risk_assessment['adjusted_risk']:.1f}/10
"""
        
        # å½±éŸ¿è©•ä¾¡
        explanation += f"""
ã€å½±éŸ¿è©•ä¾¡ã€‘
â€¢ ç”Ÿæ…‹ç³»ã¸ã®è„…å¨: {risk_assessment['ecosystem_threat']}
â€¢ äººé–“æ´»å‹•ã¸ã®å½±éŸ¿: {risk_assessment['human_impact']}
"""
        
        return explanation.strip()
    
    def _generate_fallback_reasoning(self, grid_data):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¨è«–"""
        return {
            "explanation": f"{grid_data.get('continent', 'Unknown')}ã§ç«ç½ç•°å¸¸ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚è©³ç´°åˆ†æãŒå¿…è¦ã§ã™ã€‚",
            "confidence": 0.5,
            "model": "fallback",
            "primary_factors": ["ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«ã‚ˆã‚‹åˆ¶é™ã•ã‚ŒãŸåˆ†æ"],
            "recommendations": {
                "immediate_actions": ["è©³ç´°ãƒ‡ãƒ¼ã‚¿åé›†"],
                "monitoring_enhancements": ["ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Š"]
            }
        }
    
    def batch_reasoning(self, anomaly_grids):
        """ãƒãƒƒãƒæ¨è«–å‡¦ç†"""
        results = []
        
        for idx, grid_data in anomaly_grids.iterrows():
            try:
                reasoning = self.generate_anomaly_reasoning(grid_data.to_dict())
                reasoning['grid_id'] = idx
                results.append(reasoning)
            except Exception as e:
                self.logger.error(f"âŒ ã‚°ãƒªãƒƒãƒ‰{idx}æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        return results
    
    def export_reasoning_summary(self, output_path):
        """æ¨è«–çµæœã‚µãƒãƒªãƒ¼ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not self.reasoning_history:
            self.logger.warning("æ¨è«–å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        summary = {
            "total_reasonings": len(self.reasoning_history),
            "average_confidence": np.mean([r["confidence"] for r in self.reasoning_history]),
            "risk_level_distribution": {},
            "common_factors": {},
            "timestamp": datetime.now().isoformat()
        }
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
        risk_levels = [r["risk_assessment"]["level"] for r in self.reasoning_history]
        for level in set(risk_levels):
            summary["risk_level_distribution"][level] = risk_levels.count(level)
        
        # å…±é€šè¦å› 
        all_factors = []
        for r in self.reasoning_history:
            all_factors.extend(r["primary_factors"])
        
        for factor in set(all_factors):
            summary["common_factors"][factor] = all_factors.count(factor)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"âœ… æ¨è«–ã‚µãƒãƒªãƒ¼ä¿å­˜: {output_path}")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    engine = MiniCPMReasoningEngine()
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿
    sample_grid = {
        'latitude': -15.5,
        'longitude': 28.3,
        'continent': 'Africa',
        'fire_activity': 12.5,
        'burned_area_total': 25.0,
        'anomaly_score': -0.15,
        'neighbor_max': 18.2,
        'neighbor_std': 6.8,
        'temperature_avg': 32.5,
        'precipitation_total': 15.2,
        'vegetation_index': 0.75
    }
    
    # æ¨è«–ãƒ†ã‚¹ãƒˆ
    result = engine.generate_anomaly_reasoning(sample_grid)
    print("ğŸ¤– MiniCPMæ¨è«–çµæœ:")
    print(result["explanation"])