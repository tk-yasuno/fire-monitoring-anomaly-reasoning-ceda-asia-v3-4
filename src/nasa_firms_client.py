#!/usr/bin/env python3
"""
NASA FIRMS API Client for Global Fire Monitoring System v3.0

This module provides a comprehensive client for NASA's Fire Information for
Resource Management System (FIRMS) API, designed to fetch real-time fire alert
data across all 5 continents.

Key Features:
- Real-time fire alert data collection
- Multi-satellite data sources (VIIRS, MODIS)
- Continental-level data organization
- Robust error handling and fallback simulation
- CSV data parsing and validation
- Asynchronous API calls for performance

Author: Global Disaster Monitoring Team
Version: 3.0.0
Date: 2025-09-22
"""

import logging
import aiohttp
import asyncio
import json
import os
import requests
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from io import StringIO

class NASAFIRMSClient:
    """
    Client for NASA FIRMS API integration with comprehensive data processing capabilities.
    
    Fetches real-time fire alert data from NASA Fire Information for 
    Resource Management System (FIRMS) with global coverage.
    """
    
    def __init__(self, api_key: str = None, rate_limit: float = 1.0, logger: Optional[logging.Logger] = None):
        """
        Initialize NASA FIRMS API client.
        
        Args:
            api_key (str): NASA FIRMS API key
            rate_limit (float): Delay between API calls in seconds
            logger (Optional[logging.Logger]): Custom logger instance
        """
        self.base_url = "https://firms.modaps.eosdis.nasa.gov"
        
        # Load API key from config if not provided
        if not api_key:
            try:
                config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'global_config.json')
                with open(config_path, 'r') as f:
                    config = json.load(f)
                    api_key = config.get('nasa_firms', {}).get('api_key', 'YOUR_NASA_FIRMS_API_KEY')
            except Exception as e:
                api_key = "YOUR_NASA_FIRMS_API_KEY"
        
        self.api_key = api_key
        self.rate_limit = rate_limit
        self.logger = logger or logging.getLogger(__name__)
        
        # Continental bounding boxes for FIRMS queries
        self.continental_bounds = {
            'Africa': {
                'min_lat': -35.0, 'max_lat': 37.0,
                'min_lon': -18.0, 'max_lon': 52.0
            },
            'Asia': {
                'min_lat': -10.0, 'max_lat': 80.0,
                'min_lon': 60.0, 'max_lon': 180.0
            },
            'Europe': {
                'min_lat': 35.0, 'max_lat': 75.0,
                'min_lon': -25.0, 'max_lon': 60.0
            },
            'North America': {
                'min_lat': 15.0, 'max_lat': 85.0,
                'min_lon': -180.0, 'max_lon': -50.0
            },
            'South America': {
                'min_lat': -60.0, 'max_lat': 15.0,
                'min_lon': -85.0, 'max_lon': -30.0
            }
        }
        
        # VIIRS and MODIS satellite data sources
        self.data_sources = ['VIIRS_SNPP_NRT', 'VIIRS_NOAA20_NRT', 'MODIS_C6_1']
        
        self.logger.info("ðŸ›°ï¸ NASA FIRMS client initialized")
        self.logger.info("ðŸ“Š Monitoring 5 continents")

    def validate_api_key(self) -> bool:
        """
        Validate access to NASA FIRMS archive data.
        
        Returns:
            bool: True if archive data is accessible, False otherwise
        """
        try:
            # Test access to MODIS C6.1 archive data (discovered working endpoint)
            test_url = f"{self.base_url}/data/active_fire/modis-c6.1/csv/MODIS_C6_1_Global_24h.csv"
            response = requests.get(test_url, timeout=15)
            
            if response.status_code == 200:
                content = response.text
                if 'latitude' in content and 'longitude' in content:
                    # Count lines to estimate data size
                    lines = content.count('\n')
                    self.logger.info(f"âœ… NASA FIRMS archive data accessible: ~{lines:,} data points")
                    return True
                else:
                    self.logger.warning("âš ï¸ Archive data format unexpected")
                    return False
            else:
                self.logger.warning(f"âš ï¸ Archive data not accessible (status: {response.status_code})")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Error accessing archive data: {e}")
            return False

    async def fetch_fire_alerts_for_continent(self, continent: str, session: aiohttp.ClientSession) -> Dict:
        """
        Fetch fire alerts for a specific continent from NASA FIRMS API.
        
        Args:
            continent: Continent name
            session: aiohttp session for async requests
            
        Returns:
            Dictionary containing fire alert data
        """
        try:
            # Validate API key first
            if not self.validate_api_key():
                # Fall back to simulation if no API key
                return await self._generate_simulated_data(continent)
            
            bounds = self.continental_bounds.get(continent)
            if not bounds:
                raise ValueError(f"Unknown continent: {continent}")
            
            # Build API URL using discovered working MODIS C6.1 archive
            # Real archive data: 11,204 fire alerts from global coverage
            url = f"{self.base_url}/data/active_fire/modis-c6.1/csv/MODIS_C6_1_Global_24h.csv"
            headers = {}
            
            async with session.get(url, headers=headers) as response:
                if response.status == 200:
                    csv_text = await response.text()
                    
                    # Handle empty response (no fires detected)
                    if not csv_text or csv_text.strip() == "":
                        self.logger.info(f"âœ… {continent}: No active fires detected")
                        return {
                            'continent': continent,
                            'total_alerts': 0,
                            'timestamp': datetime.now(),
                            'average_temperature': 25.0,
                            'max_temperature': 25.0,
                            'fire_intensity': 'none',
                            'data_source': 'NASA_FIRMS_REAL',
                            'coordinates': [],
                            'alert_details': []
                        }
                    
                    # Check for CSV header or valid data
                    lines = csv_text.strip().split('\n')
                    if len(lines) > 1 or (len(lines) == 1 and 'latitude' in lines[0]):
                        # Valid CSV data - filter by continent bounds for real archive data
                        self.logger.info(f"ðŸ—„ï¸ Processing {len(lines):,} lines of archive data for {continent}")
                        df = self.parse_firms_csv_response(csv_text)
                        
                        if not df.empty and 'latitude' in df.columns and 'longitude' in df.columns:
                            # Filter data for the specific continent
                            continent_df = df[
                                (df['latitude'] >= bounds['min_lat']) & 
                                (df['latitude'] <= bounds['max_lat']) &
                                (df['longitude'] >= bounds['min_lon']) & 
                                (df['longitude'] <= bounds['max_lon'])
                            ]
                            
                            if not continent_df.empty:
                                self.logger.info(f"ðŸ“Š {continent}: {len(continent_df):,} fire alerts from archive")
                                # Convert back to CSV for processing
                                filtered_csv = continent_df.to_csv(index=False)
                                return self._parse_real_firms_data(filtered_csv, continent)
                            else:
                                # No fires in this continent from archive
                                self.logger.info(f"âœ… {continent}: No fires in archive data for this region")
                                return {
                                    'continent': continent,
                                    'total_alerts': 0,
                                    'timestamp': datetime.now(),
                                    'average_temperature': 25.0,
                                    'max_temperature': 25.0,
                                    'fire_intensity': 'none',
                                    'data_source': 'NASA_FIRMS_ARCHIVE',
                                    'coordinates': [],
                                    'alert_details': []
                                }
                        else:
                            return self._parse_real_firms_data(csv_text, continent)
                    
                    # Single line with no header but contains data
                    if len(lines) == 1 and ',' in lines[0]:
                        # Add header for single data line
                        csv_with_header = "latitude,longitude,brightness,scan,track,acq_date,acq_time,satellite,confidence,version,bright_t31,frp,daynight\n" + lines[0]
                        return self._parse_real_firms_data(csv_with_header, continent)  
                    
                    # If we have minimal content, assume no fires
                    if len(csv_text.strip()) < 50:
                        self.logger.info(f"âœ… {continent}: Minimal response, likely no active fires")
                        return {
                            'continent': continent,
                            'total_alerts': 0,
                            'timestamp': datetime.now(),
                            'average_temperature': 25.0,
                            'max_temperature': 25.0,
                            'fire_intensity': 'none',
                            'data_source': 'NASA_FIRMS_REAL',
                            'coordinates': [],
                            'alert_details': []
                        }
                    else:
                        self.logger.warning(f"âš ï¸ {continent}: Unexpected response format")
                        self.logger.debug(f"Response: {csv_text[:200]}")
                        return await self._generate_simulated_data(continent)
                        
                elif response.status == 401:
                    self.logger.error(f"âŒ {continent}: API key unauthorized")
                    return await self._generate_simulated_data(continent)
                elif response.status == 404:
                    self.logger.info(f"âœ… {continent}: No data available (404)")
                    return await self._generate_simulated_data(continent)
                else:
                    self.logger.warning(f"âš ï¸ {continent}: API returned status {response.status}")
                    return await self._generate_simulated_data(continent)
                    
        except Exception as e:
            self.logger.error(f"âŒ Error fetching {continent} data: {e}")
            return await self._generate_simulated_data(continent)

    def _parse_real_firms_data(self, csv_text: str, continent: str) -> Dict:
        """
        Parse real NASA FIRMS CSV data into our format.
        
        Args:
            csv_text: Raw CSV text from FIRMS API
            continent: Continent name
            
        Returns:
            Dictionary containing parsed fire alert data
        """
        try:
            df = self.parse_firms_csv_response(csv_text)
            
            if df.empty:
                return {
                    'continent': continent,
                    'total_alerts': 0,
                    'timestamp': datetime.now(),
                    'average_temperature': 25.0,
                    'max_temperature': 25.0,
                    'fire_intensity': 'none',
                    'data_source': 'NASA_FIRMS_REAL',
                    'coordinates': [],
                    'alert_details': []
                }
            
            # Calculate statistics from real data
            total_alerts = len(df)
            
            # Extract temperature data if available
            avg_temp = df['brightness'].mean() if 'brightness' in df.columns else 300.0
            max_temp = df['brightness'].max() if 'brightness' in df.columns else 300.0
            
            # Convert from Kelvin to Celsius if needed
            if avg_temp > 200:  # Likely Kelvin
                avg_temp = avg_temp - 273.15
                max_temp = max_temp - 273.15
            
            # Determine fire intensity
            if total_alerts > 100:
                intensity = 'extreme'
            elif total_alerts > 50:
                intensity = 'high'
            elif total_alerts > 10:
                intensity = 'medium'
            else:
                intensity = 'low'
            
            # Extract coordinates
            coordinates = []
            if 'latitude' in df.columns and 'longitude' in df.columns:
                coordinates = df[['latitude', 'longitude']].values.tolist()[:100]  # Limit for performance
            
            # Satellite information
            satellites = df['satellite'].unique().tolist() if 'satellite' in df.columns else ['VIIRS']
            
            fire_data = {
                'continent': continent,
                'total_alerts': total_alerts,
                'timestamp': datetime.now(),
                'average_temperature': round(avg_temp, 1),
                'max_temperature': round(max_temp, 1),
                'fire_intensity': intensity,
                'data_source': 'NASA_FIRMS_REAL',
                'coordinates': coordinates,
                'satellites': satellites,
                'confidence_levels': df['confidence'].describe().to_dict() if 'confidence' in df.columns else {},
                'raw_data_points': len(df)
            }
            
            self.logger.info(f"ðŸ›°ï¸ {continent}: {total_alerts} real fire alerts processed")
            
            return fire_data
            
        except Exception as e:
            self.logger.error(f"Error parsing real FIRMS data for {continent}: {e}")    
            # Fall back to simulated data
            return self._generate_simulated_data_sync(continent)

    async def _generate_simulated_data(self, continent: str) -> Dict:
        """
        Generate simulated fire alert data as fallback.
        
        Args:
            continent: Continent name
            
        Returns:
            Dictionary containing simulated fire alert data
        """
        # Simulate realistic fire alert data based on continent
        continent_alert_ranges = {
            'Africa': (30, 150),
            'Asia': (20, 120),
            'Europe': (10, 60),
            'North America': (15, 80),
            'South America': (40, 200)
        }
        
        import random
        min_alerts, max_alerts = continent_alert_ranges.get(continent, (10, 50))
        total_alerts = random.randint(min_alerts, max_alerts)
        
        # Simulate temperature data with climate variation
        base_temp = {
            'Africa': 35.0,
            'Asia': 32.0,
            'Europe': 25.0,
            'North America': 28.0,
            'South America': 30.0
        }.get(continent, 25.0)
        
        avg_temp = base_temp + random.uniform(-5, 15)
        max_temp = avg_temp + random.uniform(5, 20)
        
        # Create simulated fire alert data
        fire_data = {
            'continent': continent,
            'total_alerts': total_alerts,
            'timestamp': datetime.now(),
            'average_temperature': round(avg_temp, 1),
            'max_temperature': round(max_temp, 1),
            'fire_intensity': 'simulated',
            'data_source': 'NASA_FIRMS_SIMULATED',
            'coordinates': [],
            'alert_details': []
        }
        
        return fire_data

    def _generate_simulated_data_sync(self, continent: str) -> Dict:
        """
        Generate simulated fire alert data (synchronous version).
        
        Args:
            continent: Continent name
            
        Returns:
            Dictionary containing simulated fire alert data
        """
        import random
        
        continent_alert_ranges = {
            'Africa': (30, 150),
            'Asia': (20, 120),
            'Europe': (10, 60),
            'North America': (15, 80),
            'South America': (40, 200)
        }
        
        min_alerts, max_alerts = continent_alert_ranges.get(continent, (10, 50))
        total_alerts = random.randint(min_alerts, max_alerts)
        
        base_temp = {
            'Africa': 35.0,
            'Asia': 32.0,
            'Europe': 25.0,
            'North America': 28.0,
            'South America': 30.0
        }.get(continent, 25.0)
        
        avg_temp = base_temp + random.uniform(-5, 15)
        max_temp = avg_temp + random.uniform(5, 20)
        
        return {
            'continent': continent,
            'total_alerts': total_alerts,
            'timestamp': datetime.now(),
            'average_temperature': round(avg_temp, 1),
            'max_temperature': round(max_temp, 1),
            'fire_intensity': 'simulated',
            'data_source': 'NASA_FIRMS_SIMULATED',
            'coordinates': [],
            'alert_details': []
        }

    async def collect_global_fire_data(self) -> Dict:
        """
        Collect fire alert data from all continents.
        
        Returns:
            Dictionary containing global fire alert data
        """
        global_data = {
            'timestamp': datetime.now(),
            'data_source': 'NASA_FIRMS',
            'continents': {},
            'global_summary': {}
        }
        
        try:
            continents = ['Africa', 'Asia', 'Europe', 'North America', 'South America']
            
            async with aiohttp.ClientSession() as session:
                # Collect data from all continents concurrently
                tasks = [
                    self.fetch_fire_alerts_for_continent(continent, session)
                    for continent in continents
                ]
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                total_alerts = 0
                valid_continents = 0
                
                for continent, result in zip(continents, results):
                    if isinstance(result, dict):
                        global_data['continents'][continent] = result
                        total_alerts += result.get('total_alerts', 0)
                        valid_continents += 1
                    else:
                        self.logger.error(f"Failed to fetch data for {continent}")
                
                # Calculate global summary
                global_data['global_summary'] = {
                    'total_alerts': total_alerts,
                    'active_continents': valid_continents,
                    'continents_with_data': valid_continents,
                    'collection_timestamp': datetime.now().isoformat()
                }
                
                self.logger.info(f"ðŸŒ Global collection complete: {total_alerts} total alerts")
                
        except Exception as e:
            self.logger.error(f"Error in global FIRMS data collection: {e}")
        
        return global_data

    def parse_firms_csv_response(self, csv_text: str) -> pd.DataFrame:
        """
        Parse CSV response from NASA FIRMS API with robust error handling.

        Args:
            csv_text: Raw CSV text from API

        Returns:
            Parsed DataFrame with fire alert data
        """
        try:
            # Check for empty or whitespace-only response
            if not csv_text or csv_text.strip() == "":
                self.logger.info("Empty CSV response - no fire alerts for this region")
                return pd.DataFrame()

            # Check for HTML error responses
            if csv_text.strip().startswith('<'):
                self.logger.error("Received HTML response instead of CSV data")
                return pd.DataFrame()

            # Parse CSV data
            try:
                df = pd.read_csv(StringIO(csv_text))
            except pd.errors.EmptyDataError:
                self.logger.info("No CSV data to parse - no fire alerts")
                return pd.DataFrame()
            except pd.errors.ParserError as e:
                self.logger.warning(f"CSV parsing error: {e}, attempting header detection")
                # Try without header if parsing fails
                try:
                    df = pd.read_csv(StringIO(csv_text), header=None)
                    # If successful, assign standard FIRMS column names
                    expected_cols = ['latitude', 'longitude', 'brightness', 'scan', 'track', 
                                   'acq_date', 'acq_time', 'satellite', 'confidence', 'version', 
                                   'bright_t31', 'frp', 'daynight']
                    if len(df.columns) >= len(expected_cols):
                        df.columns = expected_cols[:len(df.columns)]
                except Exception as e2:
                    self.logger.error(f"Failed to parse CSV even without header: {e2}")
                    return pd.DataFrame()

            # Validate DataFrame
            if df.empty:
                self.logger.info("Parsed CSV is empty - no fire alerts for this region")
                return df

            # Check for required columns
            required_cols = ['latitude', 'longitude']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                self.logger.error(f"Missing required columns: {missing_cols}")
                return pd.DataFrame()

            # Validate coordinate ranges
            if 'latitude' in df.columns and 'longitude' in df.columns:
                invalid_coords = (
                    (df['latitude'] < -90) | (df['latitude'] > 90) |
                    (df['longitude'] < -180) | (df['longitude'] > 180)
                )
                if invalid_coords.any():
                    self.logger.warning(f"Found {invalid_coords.sum()} rows with invalid coordinates")
                    df = df[~invalid_coords]

            # Add processing timestamp
            df['processed_at'] = datetime.now()

            # Calculate additional metrics if confidence column exists
            if 'confidence' in df.columns:
                try:
                    df['confidence_category'] = pd.cut(
                        df['confidence'],
                        bins=[0, 30, 80, 100],
                        labels=['low', 'medium', 'high']
                    )
                except Exception as e:
                    self.logger.warning(f"Failed to create confidence categories: {e}")
            
            self.logger.info(f"ðŸ“Š Parsed {len(df)} fire alerts from FIRMS")
            return df

        except Exception as e:
            self.logger.error(f"Error parsing FIRMS CSV: {e}")
            return pd.DataFrame()

    def get_available_data_sources(self) -> List[str]:
        """
        Get list of available FIRMS data sources.
        
        Returns:
            List of available data sources
        """
        return self.data_sources.copy()