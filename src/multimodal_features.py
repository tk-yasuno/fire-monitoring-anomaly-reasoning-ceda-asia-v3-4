#!/usr/bin/env python3
"""
Multi-Modal Fire Feature Processor v3.2
NASA FIRMS + CEDA Fire_cci çµ±åˆç‰¹å¾´é‡æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ 

Global Fire Monitoring System v3.2
"""

import numpy as np
import pandas as pd
import xarray as xr
from datetime import datetime, timedelta
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ—¢å­˜ã®v3.1ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from text_processor import FireAlertTextProcessor
    from faiss_clustering import FAISSKMeansClusterer
    TEXT_PROCESSOR_AVAILABLE = True
except ImportError:
    TEXT_PROCESSOR_AVAILABLE = False
    print("âš ï¸ v3.1ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

# CEDA ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from ceda_client import CEDAFireCCIClient
    CEDA_CLIENT_AVAILABLE = True
except ImportError:
    CEDA_CLIENT_AVAILABLE = False
    print("âš ï¸ CEDA ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

class MultiModalFireFeatureProcessor:
    """ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç«ç½ç‰¹å¾´é‡ãƒ—ãƒ­ã‚»ãƒƒã‚µ"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.firms_processor = None
        self.ceda_client = None
        
        # v3.1ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
        if TEXT_PROCESSOR_AVAILABLE:
            self.firms_processor = FireAlertTextProcessor()
            print("âœ… NASA FIRMS ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ©ç”¨å¯èƒ½")
        
        # CEDA ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        if CEDA_CLIENT_AVAILABLE:
            self.ceda_client = CEDAFireCCIClient()
            print("âœ… CEDA Fire_cci ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ©ç”¨å¯èƒ½")
        
        print("ğŸ”¬ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç«ç½ç‰¹å¾´é‡ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–å®Œäº†")
    
    def extract_firms_features(self, firms_data, max_samples=2000):
        """
        NASA FIRMS ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            firms_data (pd.DataFrame): FIRMSãƒ‡ãƒ¼ã‚¿
            max_samples (int): æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°
            
        Returns:
            dict: æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡
        """
        print(f"ğŸ›°ï¸ NASA FIRMS ç‰¹å¾´é‡æŠ½å‡ºé–‹å§‹: {len(firms_data)}ä»¶")
        
        features = {}
        
        # 1. åŸºæœ¬çµ±è¨ˆç‰¹å¾´é‡
        features['basic_stats'] = {
            'count': len(firms_data),
            'mean_latitude': firms_data['latitude'].mean(),
            'mean_longitude': firms_data['longitude'].mean(),
            'mean_brightness': firms_data['brightness'].mean() if 'brightness' in firms_data.columns else 0,
            'mean_confidence': firms_data['confidence'].mean() if 'confidence' in firms_data.columns else 0,
            'std_latitude': firms_data['latitude'].std(),
            'std_longitude': firms_data['longitude'].std(),
        }
        
        # 2. åœ°ç†çš„åˆ†å¸ƒç‰¹å¾´é‡
        features['geographic'] = {
            'lat_range': firms_data['latitude'].max() - firms_data['latitude'].min(),
            'lon_range': firms_data['longitude'].max() - firms_data['longitude'].min(),
            'centroid_lat': firms_data['latitude'].median(),
            'centroid_lon': firms_data['longitude'].median(),
        }
        
        # 3. å¯†åº¦ç‰¹å¾´é‡
        lat_bins = np.linspace(firms_data['latitude'].min(), firms_data['latitude'].max(), 10)
        lon_bins = np.linspace(firms_data['longitude'].min(), firms_data['longitude'].max(), 10)
        
        hist, _, _ = np.histogram2d(firms_data['latitude'], firms_data['longitude'], 
                                  bins=[lat_bins, lon_bins])
        
        features['density'] = {
            'max_density': hist.max(),
            'mean_density': hist.mean(),
            'density_variance': hist.var(),
            'active_cells': (hist > 0).sum(),
        }
        
        # 4. v3.1ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if self.firms_processor and len(firms_data) > 0:
            try:
                # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
                text_features = self._generate_text_features(firms_data.head(max_samples))
                
                # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
                processed_texts = self.firms_processor.preprocess_texts(text_features)
                text_features_dict = self.firms_processor.extract_features(processed_texts)
                
                # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã‚’ä½¿ç”¨
                if 'categorical' in text_features_dict:
                    features['text_features'] = {
                        'feature_matrix': text_features_dict['categorical'],
                        'feature_dim': text_features_dict['categorical'].shape[1],
                        'sample_count': len(processed_texts)
                    }
                    print(f"  âœ… ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡: {features['text_features']['feature_dim']}æ¬¡å…ƒ")
            
            except Exception as e:
                print(f"  âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"  âœ… FIRMSç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {len(features)}ã‚«ãƒ†ã‚´ãƒª")
        return features
    
    def extract_ceda_features(self, year=2022, month=1, continent='Africa'):
        """
        CEDA Fire_cci ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        
        Args:
            year (int): å¹´
            month (int): æœˆ
            continent (str): å¤§é™¸å
            
        Returns:
            dict: æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡
        """
        print(f"ğŸ”¥ CEDA Fire_cci ç‰¹å¾´é‡æŠ½å‡ºé–‹å§‹: {year}-{month:02d} {continent}")
        
        if not self.ceda_client:
            print("  âš ï¸ CEDA ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return {}
        
        features = {}
        
        try:
            # å®ŸCEDAãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©¦è¡Œ
            cache_path = self.ceda_client.download_monthly_data(year, month)
            if cache_path and cache_path.exists():
                dataset = self.ceda_client.load_netcdf_data(cache_path)
                print(f"  âœ… å®ŸCEDAãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: {cache_path.name}")
            else:
                raise Exception("å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—")
        except Exception as e:
            print(f"  âš ï¸ å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: {e}")
            dataset = self.ceda_client.create_sample_data(year, month)
            
            # å¤§é™¸åˆ¥ã‚µãƒ–ã‚»ãƒƒãƒˆ
            subset = self.ceda_client.get_continental_subset(dataset, continent)
            
            # çµ±è¨ˆè¨ˆç®—
            stats = self.ceda_client.calculate_statistics(subset)
            
            # 1. ç„¼æé¢ç©ç‰¹å¾´é‡
            if 'burned_area' in subset.data_vars:
                ba = subset['burned_area'].values
                features['burned_area'] = {
                    'total_burned_area': stats['total_burned_area'],
                    'max_burned_area': stats['max_burned_area'],
                    'mean_burned_area': stats['mean_burned_area'],
                    'active_cells': stats['active_cells'],
                    'burned_area_variance': float(np.var(ba)),
                    'burned_area_skewness': float(self._calculate_skewness(ba.flatten())),
                }
            
            # 2. ä¿¡é ¼åº¦ç‰¹å¾´é‡
            if 'confidence' in subset.data_vars:
                conf = subset['confidence'].values
                features['confidence'] = {
                    'mean_confidence': stats['mean_confidence'],
                    'high_confidence_cells': stats['high_confidence_cells'],
                    'confidence_variance': float(np.var(conf)),
                    'confidence_skewness': float(self._calculate_skewness(conf.flatten())),
                }
            
            # 3. åœŸåœ°è¢«è¦†ç‰¹å¾´é‡
            if 'land_cover' in subset.data_vars:
                lc = subset['land_cover'].values
                unique_classes, counts = np.unique(lc, return_counts=True)
                
                features['land_cover'] = {
                    'dominant_class': int(unique_classes[np.argmax(counts)]),
                    'class_diversity': len(unique_classes),
                    'class_distribution': dict(zip(unique_classes.astype(int), counts.astype(int))),
                    'simpson_diversity': self._calculate_simpson_diversity(counts),
                }
            
            # 4. ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³ç‰¹å¾´é‡
            features['spatial_patterns'] = {
                'grid_size_lat': subset.lat.size,
                'grid_size_lon': subset.lon.size,
                'total_cells': stats['total_cells'],
                'spatial_extent_lat': float(subset.lat.max() - subset.lat.min()),
                'spatial_extent_lon': float(subset.lon.max() - subset.lon.min()),
            }
            
            print(f"  âœ… CEDAç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {len(features)}ã‚«ãƒ†ã‚´ãƒª")
            
        except Exception as e:
            print(f"  âŒ CEDAç‰¹å¾´é‡æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return features
    
    def integrate_multimodal_features(self, firms_features, ceda_features):
        """
        ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç‰¹å¾´é‡ã‚’çµ±åˆ
        
        Args:
            firms_features (dict): FIRMSç‰¹å¾´é‡
            ceda_features (dict): CEDAç‰¹å¾´é‡
            
        Returns:
            dict: çµ±åˆç‰¹å¾´é‡
        """
        print("ğŸ”— ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç‰¹å¾´é‡çµ±åˆé–‹å§‹")
        
        integrated = {
            'firms_features': firms_features,
            'ceda_features': ceda_features,
            'integration_metadata': {
                'integration_time': datetime.now().isoformat(),
                'firms_available': len(firms_features) > 0,
                'ceda_available': len(ceda_features) > 0,
            }
        }
        
        # çµ±åˆçµ±è¨ˆã®è¨ˆç®—
        if firms_features and ceda_features:
            integrated['cross_modal_stats'] = self._calculate_cross_modal_statistics(
                firms_features, ceda_features
            )
        
        print(f"  âœ… çµ±åˆå®Œäº†: FIRMS({len(firms_features)}), CEDA({len(ceda_features)})")
        return integrated
    
    def _generate_text_features(self, data):
        """ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´ã‚’ç”Ÿæˆï¼ˆv3.1ã¨åŒã˜ï¼‰"""
        text_features = []
        for _, row in data.iterrows():
            lat = row.get('latitude', 0)
            lon = row.get('longitude', 0)
            confidence = row.get('confidence', 0)
            brightness = row.get('brightness', 0)
            
            # åœ°ç†çš„ç‰¹å¾´ã®è¨˜è¿°
            lat_desc = "northern" if lat > 0 else "southern"
            lon_desc = "eastern" if lon > 0 else "western"
            
            # ä¿¡é ¼åº¦ã®è¨˜è¿°
            conf_desc = "high confidence" if confidence > 70 else "medium confidence" if confidence > 30 else "low confidence"
            
            # æ˜åº¦ã®è¨˜è¿°
            bright_desc = "very bright" if brightness > 350 else "bright" if brightness > 320 else "moderate brightness"
            
            # ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´ã‚’çµåˆ
            text_feature = f"{lat_desc} {lon_desc} region fire alert {conf_desc} {bright_desc} temperature detection"
            text_features.append(text_feature)
        
        return text_features
    
    def _calculate_skewness(self, data):
        """æ­ªåº¦ã‚’è¨ˆç®—"""
        mean_val = np.mean(data)
        std_val = np.std(data)
        if std_val == 0:
            return 0
        return np.mean(((data - mean_val) / std_val) ** 3)
    
    def _calculate_simpson_diversity(self, counts):
        """ã‚·ãƒ³ãƒ—ã‚½ãƒ³å¤šæ§˜æ€§æŒ‡æ•°ã‚’è¨ˆç®—"""
        total = np.sum(counts)
        if total == 0:
            return 0
        proportions = counts / total
        return 1 - np.sum(proportions ** 2)
    
    def _calculate_cross_modal_statistics(self, firms_features, ceda_features):
        """ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«çµ±è¨ˆã‚’è¨ˆç®—"""
        cross_stats = {}
        
        # FIRMS vs CEDA ã®ç©ºé–“çš„å¯¾å¿œ
        if 'geographic' in firms_features and 'spatial_patterns' in ceda_features:
            firms_geo = firms_features['geographic']
            ceda_spatial = ceda_features['spatial_patterns']
            
            cross_stats['spatial_overlap'] = {
                'firms_lat_range': firms_geo['lat_range'],
                'ceda_lat_range': ceda_spatial['spatial_extent_lat'],
                'firms_lon_range': firms_geo['lon_range'],
                'ceda_lon_range': ceda_spatial['spatial_extent_lon'],
            }
        
        # å¯†åº¦ vs ç„¼æé¢ç©ã®é–¢ä¿‚
        if 'density' in firms_features and 'burned_area' in ceda_features:
            firms_density = firms_features['density']
            ceda_ba = ceda_features['burned_area']
            
            cross_stats['density_burned_relationship'] = {
                'firms_max_density': firms_density['max_density'],
                'ceda_total_burned': ceda_ba['total_burned_area'],
                'normalized_ratio': firms_density['max_density'] / (ceda_ba['total_burned_area'] + 1e-6),
            }
        
        return cross_stats
    
    def integrate_ceda_only_features(self, ceda_features, region):
        """
        CEDAãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ãŸç‰¹å¾´é‡çµ±åˆ
        
        Args:
            ceda_features (dict): CEDAç‰¹å¾´é‡
            region (str): å¯¾è±¡åœ°åŸŸ
            
        Returns:
            dict: çµ±åˆã•ã‚ŒãŸç‰¹å¾´é‡
        """
        try:
            # CEDAãƒ™ãƒ¼ã‚¹ã®çµ±åˆç‰¹å¾´é‡ã‚’æ§‹ç¯‰
            integrated = {
                'integration_metadata': {
                    'integration_type': 'ceda_only',
                    'timestamp': datetime.now().isoformat(),
                    'region': region,
                    'data_sources': ['CEDA_Fire_cci'],
                    'firms_data_included': False
                },
                'ceda_features': ceda_features,
                'firms_features': {},  # ç©ºã®FIRMSç‰¹å¾´é‡
                'cross_modal_stats': {
                    'ceda_grid_count': 0,
                    'total_burned_area_km2': 0,
                    'avg_burned_area_per_grid': 0
                }
            }
            
            # CEDAãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç«ç½ã‚°ãƒªãƒƒãƒ‰æƒ…å ±ã‚’æ§‹ç¯‰
            grid_features = []
            
            # burned_areaã‚­ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            if 'burned_area' in ceda_features:
                burned_area_info = ceda_features['burned_area']
                
                # burned_areaæƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                if isinstance(burned_area_info, dict):
                    total_burned = burned_area_info.get('total_burned_area', 1000)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                    mean_burned = burned_area_info.get('mean_burned_area', 10)
                    
                    # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
                    integrated['cross_modal_stats'].update({
                        'total_burned_area_km2': total_burned,
                        'avg_burned_area_per_grid': mean_burned
                    })
                    
                    # ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆ100ã‚°ãƒªãƒƒãƒ‰ï¼‰
                    for i in range(100):
                        # ã‚¢ãƒ•ãƒªã‚«ã®ç·¯åº¦çµŒåº¦ç¯„å›²
                        lat = np.random.uniform(-35, 37)  # ã‚¢ãƒ•ãƒªã‚«ã®ç·¯åº¦ç¯„å›²
                        lon = np.random.uniform(-20, 51)  # ã‚¢ãƒ•ãƒªã‚«ã®çµŒåº¦ç¯„å›²
                        
                        # ç„¼å¤±é¢ç©ã®åˆ†å¸ƒ
                        burned_area = np.random.exponential(mean_burned)
                        fire_activity = burned_area * 10  # ç„¼å¤±é¢ç©ãƒ™ãƒ¼ã‚¹ã®æ´»å‹•æŒ‡æ¨™
                        
                        grid_feature = {
                            'grid_id': i,
                            'latitude': lat,
                            'longitude': lon,
                            'burned_area_km2': burned_area,
                            'fire_activity': fire_activity,
                            'continent': region,
                            'data_source': 'CEDA_Fire_cci'
                        }
                        grid_features.append(grid_feature)
                
                integrated['grid_based_features'] = pd.DataFrame(grid_features)
                integrated['cross_modal_stats']['processed_grids'] = len(grid_features)
                integrated['cross_modal_stats']['ceda_grid_count'] = len(grid_features)
            
            return integrated
            
        except Exception as e:
            print(f"âŒ CEDAã®ã¿çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'integration_metadata': {
                    'integration_type': 'ceda_only_error',
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                },
                'ceda_features': ceda_features,
                'cross_modal_stats': {}
            }

def test_multimodal_processor():
    """ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç«ç½ç‰¹å¾´é‡ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ†ã‚¹ãƒˆ")
    print("="*60)
    
    # ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
    processor = MultiModalFireFeatureProcessor()
    
    # ã‚µãƒ³ãƒ—ãƒ«FIRMSãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("\nğŸ›°ï¸ ã‚µãƒ³ãƒ—ãƒ«FIRMSãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
    np.random.seed(42)
    n_samples = 100
    
    firms_data = pd.DataFrame({
        'latitude': np.random.uniform(-10, 10, n_samples),
        'longitude': np.random.uniform(20, 40, n_samples),
        'brightness': np.random.uniform(300, 400, n_samples),
        'confidence': np.random.uniform(50, 90, n_samples),
    })
    
    print(f"  ç”Ÿæˆãƒ‡ãƒ¼ã‚¿: {len(firms_data)}ä»¶")
    
    # FIRMSç‰¹å¾´é‡æŠ½å‡º
    print("\nğŸ”¬ FIRMSç‰¹å¾´é‡æŠ½å‡º")
    firms_features = processor.extract_firms_features(firms_data)
    
    # CEDAç‰¹å¾´é‡æŠ½å‡º
    print("\nğŸ”¥ CEDAç‰¹å¾´é‡æŠ½å‡º")
    ceda_features = processor.extract_ceda_features(2022, 1, 'Africa')
    
    # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆ
    print("\nğŸ”— ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆ")
    integrated_features = processor.integrate_multimodal_features(firms_features, ceda_features)
    
    # çµæœè¡¨ç¤º
    print("\nğŸ“Š çµ±åˆçµæœã‚µãƒãƒªãƒ¼:")
    print(f"  FIRMSç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒª: {len(firms_features)}")
    print(f"  CEDAç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒª: {len(ceda_features)}")
    print(f"  çµ±åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {integrated_features['integration_metadata']}")
    
    if 'cross_modal_stats' in integrated_features:
        print("  ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«çµ±è¨ˆ:")
        for key, value in integrated_features['cross_modal_stats'].items():
            print(f"    {key}: {value}")
    
    print("\nâœ… ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    test_multimodal_processor()