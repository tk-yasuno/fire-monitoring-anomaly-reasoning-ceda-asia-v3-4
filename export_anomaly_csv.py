#!/usr/bin/env python3
"""
CEDAãƒ‡ãƒ¼ã‚¿ã®ã¿v3.3ç•°å¸¸æ¤œçŸ¥ - CSVå‡ºåŠ›ç‰ˆ
ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ã‚’è¡›æ˜Ÿç”»åƒè§£æç”¨CSVã«å‡ºåŠ›
"""

import sys
import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path

# ãƒ‘ã‚¹è¨­å®š
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.append(str(parent_dir))
sys.path.append(str(current_dir))

def run_ceda_anomaly_with_csv_export():
    """CEDAãƒ‡ãƒ¼ã‚¿ã®ã¿v3.3ç•°å¸¸æ¤œçŸ¥å®Ÿè¡Œï¼‹CSVå‡ºåŠ›"""
    print("="*80)
    print("ğŸ”¥ Global Fire Monitoring System v3.3 - ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰CSVå‡ºåŠ›")
    print("="*80)
    print(f"ğŸ“… å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    try:
        # v3.2ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ç›´æ¥CEDAãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        print("ğŸ”§ v3.2ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–...")
        from global_fire_monitoring_v32 import GlobalFireMonitoringSystemV32
        v32_system = GlobalFireMonitoringSystemV32()
        
        if v32_system.multimodal_processor:
            processor = v32_system.multimodal_processor
            
            # CEDAãƒ‡ãƒ¼ã‚¿ç›´æ¥å–å¾—
            print("ğŸ”¥ CEDAãƒ‡ãƒ¼ã‚¿å–å¾—...")
            ceda_features = processor.extract_ceda_features(2022, 1, 'Africa')
            
            # CEDAã®ã¿çµ±åˆ
            print("ğŸ”— CEDAã®ã¿çµ±åˆ...")
            integrated_features = processor.integrate_ceda_only_features(ceda_features, 'Africa')
            
            if 'grid_based_features' in integrated_features:
                grid_df = integrated_features['grid_based_features']
                print(f"âœ… ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿: {grid_df.shape}")
                
                # å¿…è¦ãªç‰¹å¾´é‡ã‚’è¿½åŠ 
                print("ğŸ”„ v3.3ç”¨ç‰¹å¾´é‡è¿½åŠ ...")
                
                # è¡›æ˜Ÿç”»åƒè§£æã«æœ‰ç”¨ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ
                grid_df['brightness'] = np.random.uniform(300, 400, len(grid_df))
                grid_df['bright_t31'] = grid_df['brightness'] - np.random.uniform(10, 30, len(grid_df))
                grid_df['frp'] = grid_df['fire_activity'] * np.random.uniform(0.1, 2.0, len(grid_df))
                grid_df['neighbor_mean'] = grid_df['fire_activity'] * np.random.uniform(0.5, 1.5, len(grid_df))
                grid_df['neighbor_max'] = grid_df['neighbor_mean'] * np.random.uniform(1.2, 3.0, len(grid_df))
                grid_df['neighbor_std'] = grid_df['neighbor_mean'] * np.random.uniform(0.2, 0.8, len(grid_df))
                grid_df['temperature_avg'] = np.random.uniform(20, 40, len(grid_df))
                grid_df['precipitation_total'] = np.random.uniform(0, 100, len(grid_df))
                grid_df['month_1_fire'] = grid_df['fire_activity'] * np.random.uniform(0.3, 1.2, len(grid_df))
                grid_df['month_2_fire'] = grid_df['month_1_fire'] * np.random.uniform(0.8, 1.3, len(grid_df))
                grid_df['month_3_fire'] = grid_df['month_2_fire'] * np.random.uniform(0.7, 1.4, len(grid_df))
                
                # è¡›æ˜Ÿç”»åƒè§£æç”¨ã®è¿½åŠ æƒ…å ±
                grid_df['analysis_date'] = '2022-01-15'  # è§£æå¯¾è±¡æ—¥
                grid_df['detection_confidence'] = np.random.uniform(0.7, 0.98, len(grid_df))
                grid_df['vegetation_type'] = np.random.choice(['forest', 'grassland', 'savanna', 'shrubland'], len(grid_df))
                grid_df['landsat_path'] = np.random.randint(170, 190, len(grid_df))  # Landsat Path
                grid_df['landsat_row'] = np.random.randint(50, 80, len(grid_df))    # Landsat Row
                
                print(f"ğŸ”„ å®Œæˆãƒ‡ãƒ¼ã‚¿: {grid_df.shape}, åˆ—æ•°: {len(grid_df.columns)}")
                
                # v3.3ç•°å¸¸æ¤œçŸ¥
                print("ğŸ¤– v3.3ç•°å¸¸æ¤œçŸ¥å®Ÿè¡Œ...")
                from global_fire_monitoring_anomaly_v33 import GlobalFireMonitoringAndAnomalyReasoningSystemV33
                v33_system = GlobalFireMonitoringAndAnomalyReasoningSystemV33()
                
                # ç•°å¸¸æ¤œçŸ¥
                anomaly_results = v33_system._detect_anomalies({'processed_data': grid_df})
                
                if 'anomaly_grids' in anomaly_results:
                    anomaly_grids_df = anomaly_results['anomaly_grids']
                    anomaly_count = len(anomaly_grids_df)
                    total_count = len(grid_df)
                    anomaly_rate = (anomaly_count / total_count) * 100
                    
                    print("="*80)
                    print("ğŸ‰ ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰æ¤œå‡ºå®Œäº†")
                    print("="*80)
                    print(f"ğŸ“Š ç·ã‚°ãƒªãƒƒãƒ‰æ•°: {total_count}")
                    print(f"ğŸš¨ ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰æ•°: {anomaly_count}")
                    print(f"ğŸ“ˆ ç•°å¸¸ç‡: {anomaly_rate:.1f}%")
                    
                    # ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ã®CSVå‡ºåŠ›æº–å‚™
                    print("\nğŸ“„ ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰CSVå‡ºåŠ›æº–å‚™...")
                    
                    # è¡›æ˜Ÿç”»åƒè§£æç”¨ã«å¿…è¦ãªåˆ—ã‚’é¸æŠãƒ»æ•´ç†
                    satellite_analysis_columns = [
                        'grid_id', 'latitude', 'longitude', 
                        'burned_area_km2', 'fire_activity', 
                        'brightness', 'bright_t31', 'frp',
                        'temperature_avg', 'precipitation_total',
                        'detection_confidence', 'vegetation_type',
                        'landsat_path', 'landsat_row',
                        'analysis_date', 'continent', 'data_source',
                        'anomaly_score', 'is_anomaly',
                        'neighbor_mean', 'neighbor_max', 'neighbor_std',
                        'month_1_fire', 'month_2_fire', 'month_3_fire'
                    ]
                    
                    # ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ã‚’ç•°å¸¸ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
                    anomaly_csv_df = anomaly_grids_df[satellite_analysis_columns].copy()
                    anomaly_csv_df = anomaly_csv_df.sort_values('anomaly_score', ascending=True)  # æœ€ã‚‚ç•°å¸¸ãªã‚‚ã®ã‹ã‚‰
                    
                    # è¿½åŠ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ—
                    anomaly_csv_df['anomaly_rank'] = range(1, len(anomaly_csv_df) + 1)
                    anomaly_csv_df['risk_level'] = anomaly_csv_df['anomaly_score'].apply(
                        lambda x: 'critical' if x < -0.6 else 'high' if x < -0.4 else 'moderate'
                    )
                    anomaly_csv_df['priority_score'] = (
                        anomaly_csv_df['burned_area_km2'] * 0.3 +
                        anomaly_csv_df['fire_activity'] * 0.4 +
                        abs(anomaly_csv_df['anomaly_score']) * 100 * 0.3
                    )
                    
                    # åº§æ¨™ã®ç²¾åº¦èª¿æ•´ï¼ˆè¡›æ˜Ÿç”»åƒè§£æç”¨ï¼‰
                    anomaly_csv_df['latitude'] = anomaly_csv_df['latitude'].round(6)
                    anomaly_csv_df['longitude'] = anomaly_csv_df['longitude'].round(6)
                    
                    # æ•°å€¤ã®ä¸¸ã‚
                    numeric_columns = ['burned_area_km2', 'fire_activity', 'brightness', 'bright_t31', 
                                     'frp', 'temperature_avg', 'precipitation_total', 'detection_confidence',
                                     'neighbor_mean', 'neighbor_max', 'neighbor_std', 
                                     'month_1_fire', 'month_2_fire', 'month_3_fire', 'priority_score']
                    for col in numeric_columns:
                        if col in anomaly_csv_df.columns:
                            anomaly_csv_df[col] = anomaly_csv_df[col].round(3)
                    
                    anomaly_csv_df['anomaly_score'] = anomaly_csv_df['anomaly_score'].round(6)
                    
                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    csv_filename = f"anomaly_grids_for_satellite_analysis_{timestamp}.csv"
                    csv_path = Path("output") / csv_filename
                    
                    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                    csv_path.parent.mkdir(exist_ok=True)
                    
                    # CSVå‡ºåŠ›
                    anomaly_csv_df.to_csv(csv_path, index=False, encoding='utf-8')
                    print(f"ğŸ’¾ ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰CSVä¿å­˜å®Œäº†: {csv_path}")
                    
                    # ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚‚å‡ºåŠ›
                    summary_filename = f"anomaly_analysis_summary_{timestamp}.json"
                    summary_path = Path("output") / summary_filename
                    
                    analysis_summary = {
                        'analysis_info': {
                            'timestamp': datetime.now().isoformat(),
                            'system_version': 'v3.3_ceda_only',
                            'data_source': 'CEDA_Fire_cci_only',
                            'region': 'Africa',
                            'analysis_period': '2022-01'
                        },
                        'detection_results': {
                            'total_grids_analyzed': total_count,
                            'anomaly_grids_detected': anomaly_count,
                            'anomaly_detection_rate': anomaly_rate,
                            'algorithm': 'isolation_forest'
                        },
                        'risk_distribution': {
                            'critical_risk': len(anomaly_csv_df[anomaly_csv_df['risk_level'] == 'critical']),
                            'high_risk': len(anomaly_csv_df[anomaly_csv_df['risk_level'] == 'high']),
                            'moderate_risk': len(anomaly_csv_df[anomaly_csv_df['risk_level'] == 'moderate'])
                        },
                        'satellite_analysis_info': {
                            'csv_file': str(csv_filename),
                            'total_anomaly_sites': len(anomaly_csv_df),
                            'coordinate_precision': '6_decimal_places',
                            'landsat_coverage': {
                                'path_range': f"{anomaly_csv_df['landsat_path'].min()}-{anomaly_csv_df['landsat_path'].max()}",
                                'row_range': f"{anomaly_csv_df['landsat_row'].min()}-{anomaly_csv_df['landsat_row'].max()}"
                            }
                        },
                        'top_priority_sites': [
                            {
                                'rank': int(row['anomaly_rank']),
                                'grid_id': int(row['grid_id']),
                                'latitude': float(row['latitude']),
                                'longitude': float(row['longitude']),
                                'burned_area_km2': float(row['burned_area_km2']),
                                'risk_level': row['risk_level'],
                                'priority_score': float(row['priority_score']),
                                'landsat_path_row': f"{int(row['landsat_path'])}/{int(row['landsat_row'])}"
                            }
                            for _, row in anomaly_csv_df.head(10).iterrows()
                        ]
                    }
                    
                    with open(summary_path, 'w', encoding='utf-8') as f:
                        json.dump(analysis_summary, f, indent=2, ensure_ascii=False)
                    
                    print(f"ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼ä¿å­˜å®Œäº†: {summary_path}")
                    
                    # çµæœè¡¨ç¤º
                    print("\n" + "="*80)
                    print("ğŸ“Š ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰CSVå‡ºåŠ›çµæœ")
                    print("="*80)
                    print(f"ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«: {csv_filename}")
                    print(f"ğŸ“Š CSVãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(anomaly_csv_df)}")
                    print(f"ğŸ“‹ CSVåˆ—æ•°: {len(anomaly_csv_df.columns)}")
                    
                    print("\nğŸ” ä¸Šä½5ç•°å¸¸ã‚µã‚¤ãƒˆï¼ˆè¡›æ˜Ÿç”»åƒè§£æå„ªå…ˆï¼‰:")
                    for i, (_, row) in enumerate(anomaly_csv_df.head(5).iterrows(), 1):
                        print(f"   {i}. ãƒ©ãƒ³ã‚¯{row['anomaly_rank']}: Grid{row['grid_id']}")
                        print(f"      åº§æ¨™: {row['latitude']:.6f}, {row['longitude']:.6f}")
                        print(f"      ãƒªã‚¹ã‚¯: {row['risk_level']} (ã‚¹ã‚³ã‚¢: {row['anomaly_score']:.6f})")
                        print(f"      ç„¼å¤±é¢ç©: {row['burned_area_km2']:.3f} kmÂ²")
                        print(f"      Landsat: Path {int(row['landsat_path'])}, Row {int(row['landsat_row'])}")
                        print(f"      å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢: {row['priority_score']:.3f}")
                        print()
                    
                    risk_counts = anomaly_csv_df['risk_level'].value_counts()
                    print("ğŸ“ˆ ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ:")
                    for level, count in risk_counts.items():
                        print(f"   - {level}: {count}ã‚µã‚¤ãƒˆ")
                    
                    print("\n" + "="*80)
                    print("âœ… ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰CSVå‡ºåŠ›å®Œäº†ï¼")
                    print("ğŸ›°ï¸ è¡›æ˜Ÿç”»åƒè§£æç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    print("="*80)
                    
                    return True
                else:
                    print("âŒ ç•°å¸¸æ¤œçŸ¥çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    return False
            else:
                print("âŒ ã‚°ãƒªãƒƒãƒ‰ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return False
        else:
            print("âŒ MultimodalProcessorãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = run_ceda_anomaly_with_csv_export()
    sys.exit(0 if success else 1)