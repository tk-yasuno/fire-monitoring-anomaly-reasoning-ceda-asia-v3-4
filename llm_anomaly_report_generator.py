#!/usr/bin/env python3
"""
LLM-based Anomaly Grid Report Generator for v3.3
MiniCPMã¾ãŸã¯ä»£æ›¿LLMã‚’ä½¿ç”¨ã—ãŸç•°å¸¸ã‚°ãƒªãƒƒãƒ‰èª¬æ˜ç”Ÿæˆ
"""

import sys
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
import json
import re

# ãƒ‘ã‚¹è¨­å®š
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.append(str(parent_dir))
sys.path.append(str(current_dir))

class AnomalyGridLLMReporter:
    """LLMãƒ™ãƒ¼ã‚¹ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰èª¬æ˜ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.report_filename = f"v33_llm_anomaly_report_{self.timestamp}.md"
        
        # MiniCPMåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        self.minicpm_available = self._check_minicpm_availability()
        
        print(f"ğŸ¤– LLM-based Anomaly Report Generator")
        print(f"ğŸ“„ Output: {self.report_filename}")
        print(f"ğŸ”§ MiniCPM Available: {'âœ…' if self.minicpm_available else 'âŒ (Using fallback)'}")
    
    def _check_minicpm_availability(self):
        """MiniCPMåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            # MiniCPMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç¢ºèª
            # import torch
            # from transformers import AutoTokenizer, AutoModelForCausalLM
            return False  # ç¾åœ¨ã¯ä»£æ›¿å®Ÿè£…
        except ImportError:
            return False
    
    def generate_grid_explanation(self, grid_data, context_data=None):
        """å€‹åˆ¥ã‚°ãƒªãƒƒãƒ‰ã®èª¬æ˜ç”Ÿæˆ"""
        
        # åŸºæœ¬æƒ…å ±æŠ½å‡º
        lat = grid_data['latitude']
        lon = grid_data['longitude']
        burned_area = grid_data['burned_area_km2']
        fire_activity = grid_data['fire_activity']
        anomaly_score = grid_data['anomaly_score']
        
        # åœ°ç†çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¨å®š
        geographic_context = self._infer_geographic_context(lat, lon)
        
        # ç«ç½è¦æ¨¡åˆ†é¡
        fire_magnitude = self._classify_fire_magnitude(burned_area)
        
        # ç•°å¸¸åº¦åˆ†é¡
        anomaly_severity = self._classify_anomaly_severity(anomaly_score)
        
        # LLMé¢¨èª¬æ˜ç”Ÿæˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        explanation = self._generate_explanation_text(
            lat, lon, burned_area, fire_activity, anomaly_score,
            geographic_context, fire_magnitude, anomaly_severity
        )
        
        return {
            'grid_id': grid_data.get('grid_id', 'Unknown'),
            'coordinates': f"{lat:.6f}Â°N, {lon:.6f}Â°E",
            'geographic_context': geographic_context,
            'fire_magnitude': fire_magnitude,
            'anomaly_severity': anomaly_severity,
            'explanation': explanation,
            'technical_details': {
                'burned_area_km2': burned_area,
                'fire_activity_index': fire_activity,
                'anomaly_score': anomaly_score
            }
        }
    
    def _infer_geographic_context(self, lat, lon):
        """åœ°ç†çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¨å®š"""
        
        # ã‚¢ãƒ•ãƒªã‚«ã®ä¸»è¦åœ°åŸŸåˆ¤å®š
        if 5 <= lat <= 15 and -20 <= lon <= 20:
            if -5 <= lon <= 5:
                return "è¥¿ã‚¢ãƒ•ãƒªã‚«ãƒ»ã‚®ãƒ‹ã‚¢æ¹¾æ²¿å²¸åœ°åŸŸï¼ˆã‚¬ãƒ¼ãƒŠãƒ»ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢å‘¨è¾ºï¼‰"
            elif 5 <= lon <= 20:
                return "ä¸­å¤®ã‚¢ãƒ•ãƒªã‚«ãƒ»ãƒãƒ£ãƒ‰æ¹–å‘¨è¾ºï¼ˆã‚«ãƒ¡ãƒ«ãƒ¼ãƒ³ãƒ»ãƒãƒ£ãƒ‰å›½å¢ƒï¼‰"
        elif 5 <= lat <= 15 and 20 <= lon <= 40:
            return "æ±ã‚¢ãƒ•ãƒªã‚«ãƒ»ã‚¹ãƒ¼ãƒ€ãƒ³é«˜åŸï¼ˆã‚¹ãƒ¼ãƒ€ãƒ³ãƒ»å—ã‚¹ãƒ¼ãƒ€ãƒ³ï¼‰"
        elif 5 <= lat <= 15 and 40 <= lon <= 52:
            return "ã‚¢ãƒ•ãƒªã‚«ã®è§’ãƒ»ã‚¨ãƒã‚ªãƒ”ã‚¢é«˜åŸ"
        elif -10 <= lat <= 5 and 10 <= lon <= 30:
            return "ä¸­å¤®ã‚¢ãƒ•ãƒªã‚«ãƒ»ã‚³ãƒ³ã‚´ç›†åœ°"
        elif -35 <= lat <= -10 and 15 <= lon <= 35:
            return "å—éƒ¨ã‚¢ãƒ•ãƒªã‚«ãƒ»ã‚µãƒãƒ³ãƒŠåœ°å¸¯"
        else:
            return "ã‚¢ãƒ•ãƒªã‚«å¤§é™¸ãƒ»è©³ç´°åœ°åŸŸä¸æ˜"
    
    def _classify_fire_magnitude(self, burned_area):
        """ç«ç½è¦æ¨¡åˆ†é¡"""
        if burned_area > 500_000_000:  # 500M kmÂ²
            return "è¶…å¤§è¦æ¨¡ç«ç½ï¼ˆå›½å®¶ãƒ¬ãƒ™ãƒ«å½±éŸ¿ï¼‰"
        elif burned_area > 100_000_000:  # 100M kmÂ²
            return "å¤§è¦æ¨¡ç«ç½ï¼ˆåœ°åŸŸãƒ¬ãƒ™ãƒ«å½±éŸ¿ï¼‰"
        elif burned_area > 10_000_000:   # 10M kmÂ²
            return "ä¸­è¦æ¨¡ç«ç½ï¼ˆåœ°æ–¹ãƒ¬ãƒ™ãƒ«å½±éŸ¿ï¼‰"
        else:
            return "å°è¦æ¨¡ç«ç½ï¼ˆå±€åœ°çš„å½±éŸ¿ï¼‰"
    
    def _classify_anomaly_severity(self, anomaly_score):
        """ç•°å¸¸åº¦åˆ†é¡"""
        if anomaly_score < -0.6:
            return "æ¥µåº¦ã®ç•°å¸¸ï¼ˆå³åº§ã®å¯¾å¿œå¿…è¦ï¼‰"
        elif anomaly_score < -0.5:
            return "é«˜åº¦ã®ç•°å¸¸ï¼ˆå„ªå…ˆçš„ç›£è¦–å¿…è¦ï¼‰"
        elif anomaly_score < -0.4:
            return "ä¸­åº¦ã®ç•°å¸¸ï¼ˆç¶™ç¶šç›£è¦–æ¨å¥¨ï¼‰"
        else:
            return "è»½åº¦ã®ç•°å¸¸ï¼ˆé€šå¸¸ç›£è¦–ç¯„å›²ï¼‰"
    
    def _generate_explanation_text(self, lat, lon, burned_area, fire_activity, 
                                 anomaly_score, geo_context, fire_mag, anomaly_sev):
        """LLMé¢¨èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        
        # è¤‡æ•°ã®èª¬æ˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é¸æŠ
        explanations = [
            f"""
ã“ã®ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ã¯{geo_context}ã«ä½ç½®ã—ã€{fire_mag}ã«åˆ†é¡ã•ã‚Œã¾ã™ã€‚
ç„¼å¤±é¢ç©{burned_area:,.0f}kmÂ²ã¨ã„ã†æ•°å€¤ã¯ã€ã“ã®åœ°åŸŸã®é€šå¸¸ã®ç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å¤§ããé€¸è„±ã—ã¦ãŠã‚Šã€
ç•°å¸¸ã‚¹ã‚³ã‚¢{anomaly_score:.3f}ãŒç¤ºã™ã‚ˆã†ã«{anomaly_sev}çŠ¶æ…‹ã«ã‚ã‚Šã¾ã™ã€‚

ã“ã®è¦æ¨¡ã®ç«ç½ã¯ã€ä»¥ä¸‹ã®è¦å› ãŒè¤‡åˆçš„ã«ä½œç”¨ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼š
1. ç•°å¸¸ãªæ°—è±¡æ¡ä»¶ï¼ˆé•·æœŸå¹²ã°ã¤ã€å¼·é¢¨ç­‰ï¼‰
2. äººç‚ºçš„è¦å› ï¼ˆè¾²æ¥­ç‡ƒç„¼ã€åœŸåœ°é–‹ç™ºç­‰ï¼‰
3. æ¤ç”Ÿã®è“„ç©ï¼ˆéå»ã®ç«ç½æŠ‘åˆ¶ã«ã‚ˆã‚‹å¯ç‡ƒç‰©å¢—åŠ ï¼‰
4. åœ°å½¢çš„è¦å› ï¼ˆé¢¨ã®é€šã‚Šé“ã€è°·åœ°å½¢ç­‰ï¼‰

ã“ã®ç•°å¸¸ã¯è¡›æ˜Ÿè¦³æ¸¬ã«ã‚ˆã‚Šæ¤œå‡ºã•ã‚Œã€æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆIsolation Forestï¼‰ã«ã‚ˆã£ã¦
é€šå¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã®é€¸è„±ã¨ã—ã¦ç‰¹å®šã•ã‚Œã¾ã—ãŸã€‚ç¶™ç¶šçš„ãªç›£è¦–ã¨ç¾åœ°èª¿æŸ»ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚
            """.strip(),
            
            f"""
åº§æ¨™{lat:.6f}Â°N, {lon:.6f}Â°Eã®ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ã¯ã€{geo_context}ã«ãŠã„ã¦
è¦³æ¸¬ã•ã‚ŒãŸ{fire_mag}ã§ã™ã€‚

ESA Fire_cciè¡›æ˜Ÿãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ã¨ã€ã“ã®åœ°ç‚¹ã§ã®ç„¼å¤±é¢ç©{burned_area:,.0f}kmÂ²ã¯
åœ°åŸŸã®ç«ç½æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰çµ±è¨ˆçš„ã«æœ‰æ„ã«é€¸è„±ã—ã¦ãŠã‚Šã€ç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒ
{anomaly_sev}ã¨ã—ã¦åˆ†é¡ã—ã¾ã—ãŸï¼ˆç•°å¸¸ã‚¹ã‚³ã‚¢: {anomaly_score:.3f}ï¼‰ã€‚

ã“ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èƒŒæ™¯ã«ã¯ä»¥ä¸‹ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ï¼š
â€¢ å­£ç¯€çš„è¦å› ï¼šä¹¾å­£ã®å»¶é•·ã‚„é™æ°´ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¤‰åŒ–
â€¢ äººé–“æ´»å‹•ï¼šè¾²æ¥­ç®¡ç†ã€ç‰§ç•œæ´»å‹•ã€éƒ½å¸‚é–‹ç™ºåœ§åŠ›
â€¢ ç”Ÿæ…‹ç³»å¤‰åŒ–ï¼šæ¤ç”Ÿé·ç§»ã€å¤–æ¥ç¨®ä¾µå…¥ã€ç”Ÿç‰©å¤šæ§˜æ€§å¤‰åŒ–  
â€¢ æ°—å€™å¤‰å‹•ï¼šæ¸©åº¦ä¸Šæ˜‡ã€é™æ°´é‡å¤‰å‹•ã€æ¥µç«¯æ°—è±¡é »åº¦å¢—åŠ 

ã“ã®æƒ…å ±ã¯é˜²ç½è¨ˆç”»ã€åœŸåœ°åˆ©ç”¨ç®¡ç†ã€æ°—å€™å¤‰å‹•é©å¿œç­–ã®ç­–å®šã«æ´»ç”¨ã§ãã¾ã™ã€‚
            """.strip()
        ]
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆå®Ÿéš›ã®LLMã§ã¯å…¥åŠ›ã«åŸºã¥ã„ã¦ç”Ÿæˆï¼‰
        import random
        return random.choice(explanations)
    
    def generate_comprehensive_report(self, anomaly_grids_df, all_data_df):
        """åŒ…æ‹¬çš„ãªç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        print("ğŸ“ åŒ…æ‹¬çš„LLMãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        
        # å€‹åˆ¥ã‚°ãƒªãƒƒãƒ‰åˆ†æ
        grid_analyses = []
        for idx, row in anomaly_grids_df.iterrows():
            analysis = self.generate_grid_explanation(row)
            grid_analyses.append(analysis)
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        stats = self._generate_statistical_summary(anomaly_grids_df, all_data_df)
        
        # åœ°åŸŸãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        regional_patterns = self._analyze_regional_patterns(grid_analyses)
        
        # ç·åˆè©•ä¾¡
        overall_assessment = self._generate_overall_assessment(stats, regional_patterns)
        
        # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_content = self._create_markdown_report(
            grid_analyses, stats, regional_patterns, overall_assessment
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(self.report_filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… LLMãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {self.report_filename}")
        
        return self.report_filename
    
    def _generate_statistical_summary(self, anomaly_grids_df, all_data_df):
        """çµ±è¨ˆã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        return {
            'total_grids': len(all_data_df),
            'anomaly_grids': len(anomaly_grids_df),
            'anomaly_rate': len(anomaly_grids_df) / len(all_data_df) * 100,
            'total_burned_area': anomaly_grids_df['burned_area_km2'].sum(),
            'avg_burned_area': anomaly_grids_df['burned_area_km2'].mean(),
            'max_burned_area': anomaly_grids_df['burned_area_km2'].max(),
            'avg_anomaly_score': anomaly_grids_df['anomaly_score'].mean(),
            'min_anomaly_score': anomaly_grids_df['anomaly_score'].min()
        }
    
    def _analyze_regional_patterns(self, grid_analyses):
        """åœ°åŸŸãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        
        # åœ°åŸŸåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        regional_groups = {}
        for analysis in grid_analyses:
            region = analysis['geographic_context']
            if region not in regional_groups:
                regional_groups[region] = []
            regional_groups[region].append(analysis)
        
        # åœ°åŸŸåˆ¥é›†è¨ˆ
        regional_summary = {}
        for region, grids in regional_groups.items():
            regional_summary[region] = {
                'count': len(grids),
                'avg_burned_area': np.mean([g['technical_details']['burned_area_km2'] for g in grids]),
                'fire_magnitudes': [g['fire_magnitude'] for g in grids]
            }
        
        return regional_summary
    
    def _generate_overall_assessment(self, stats, regional_patterns):
        """ç·åˆè©•ä¾¡ç”Ÿæˆ"""
        
        # é‡è¦åº¦åˆ¤å®š
        if stats['anomaly_rate'] > 15:
            severity = "é«˜ãƒªã‚¹ã‚¯çŠ¶æ³"
        elif stats['anomaly_rate'] > 10:
            severity = "ä¸­ãƒªã‚¹ã‚¯çŠ¶æ³"
        else:
            severity = "ä½ãƒªã‚¹ã‚¯çŠ¶æ³"
        
        # ä¸»è¦ãªæ‡¸å¿µåœ°åŸŸ
        top_region = max(regional_patterns.items(), key=lambda x: x[1]['count'])
        
        assessment = f"""
## ç·åˆè©•ä¾¡ï¼š{severity}

### ä¸»è¦ãªç™ºè¦‹
- ç•°å¸¸ç‡ï¼š{stats['anomaly_rate']:.1f}% ({stats['anomaly_grids']}å€‹/{stats['total_grids']}å€‹)
- ç·ç„¼å¤±é¢ç©ï¼š{stats['total_burned_area']:,.0f} kmÂ²
- æœ€å¤§å˜ä½“ç«ç½ï¼š{stats['max_burned_area']:,.0f} kmÂ²
- æœ€ã‚‚å½±éŸ¿ã®å¤§ãã„åœ°åŸŸï¼š{top_region[0]} ({top_region[1]['count']}å€‹ã®ç•°å¸¸)

### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. **å³åº§ã®å¯¾å¿œ**: è¶…å¤§è¦æ¨¡ç«ç½ã‚¨ãƒªã‚¢ã®ç¾åœ°èª¿æŸ»
2. **ç¶™ç¶šç›£è¦–**: ç•°å¸¸ã‚¹ã‚³ã‚¢-0.5ä»¥ä¸‹ã®ã‚°ãƒªãƒƒãƒ‰ã®24æ™‚é–“ç›£è¦–
3. **äºˆé˜²æªç½®**: é«˜ãƒªã‚¹ã‚¯åœ°åŸŸã§ã®äºˆé˜²çš„æªç½®æ¤œè¨
4. **ãƒ‡ãƒ¼ã‚¿å…±æœ‰**: é–¢é€£æ©Ÿé–¢ã¸ã®æƒ…å ±å…±æœ‰ã¨é€£æºå¼·åŒ–

ã“ã®åˆ†æã¯å®ŸCEDAãƒ‡ãƒ¼ã‚¿ï¼ˆESA Fire_cci v5.1ï¼‰ã«åŸºã¥ãæ©Ÿæ¢°å­¦ç¿’ç•°å¸¸æ¤œçŸ¥ã®çµæœã§ã‚ã‚Šã€
ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ãŸå®¢è¦³çš„è©•ä¾¡ã§ã™ã€‚
        """.strip()
        
        return assessment
    
    def _create_markdown_report(self, grid_analyses, stats, regional_patterns, overall_assessment):
        """Markdownãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        
        report = f"""# ğŸ”¥ Global Fire Monitoring v3.3 - LLMç•°å¸¸ã‚°ãƒªãƒƒãƒ‰åˆ†æå ±å‘Š

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  
**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: ESA Fire_cci v5.1 (Real CEDA Data)  
**åˆ†ææ‰‹æ³•**: Isolation Forest + LLMèª¬æ˜ç”Ÿæˆ  
**å¯¾è±¡åœ°åŸŸ**: ã‚¢ãƒ•ãƒªã‚«å¤§é™¸  

---

{overall_assessment}

---

## ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼

| é …ç›® | å€¤ |
|------|-----|
| ç·è§£æã‚°ãƒªãƒƒãƒ‰æ•° | {stats['total_grids']:,} |
| ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰æ•° | {stats['anomaly_grids']:,} |
| ç•°å¸¸ç‡ | {stats['anomaly_rate']:.1f}% |
| ç·ç„¼å¤±é¢ç© | {stats['total_burned_area']:,.0f} kmÂ² |
| å¹³å‡ç„¼å¤±é¢ç© | {stats['avg_burned_area']:,.0f} kmÂ² |
| æœ€å¤§ç„¼å¤±é¢ç© | {stats['max_burned_area']:,.0f} kmÂ² |
| å¹³å‡ç•°å¸¸ã‚¹ã‚³ã‚¢ | {stats['avg_anomaly_score']:.3f} |
| æœ€ä½ç•°å¸¸ã‚¹ã‚³ã‚¢ | {stats['min_anomaly_score']:.3f} |

---

## ğŸ—ºï¸ åœ°åŸŸåˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ

"""
        
        for region, data in regional_patterns.items():
            report += f"""### {region}
- **ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰æ•°**: {data['count']}å€‹
- **å¹³å‡ç„¼å¤±é¢ç©**: {data['avg_burned_area']:,.0f} kmÂ²
- **ç«ç½è¦æ¨¡åˆ†å¸ƒ**: {', '.join(set(data['fire_magnitudes']))}

"""
        
        report += """---

## ğŸ” å€‹åˆ¥ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰è©³ç´°åˆ†æ

"""
        
        for i, analysis in enumerate(grid_analyses, 1):
            report += f"""### ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ #{analysis['grid_id']} ({i}/{len(grid_analyses)})

**ğŸ“ ä½ç½®**: {analysis['coordinates']}  
**ğŸŒ åœ°åŸŸ**: {analysis['geographic_context']}  
**ğŸ”¥ ç«ç½è¦æ¨¡**: {analysis['fire_magnitude']}  
**âš ï¸ ç•°å¸¸ãƒ¬ãƒ™ãƒ«**: {analysis['anomaly_severity']}  

#### è©³ç´°åˆ†æ
{analysis['explanation']}

#### æŠ€è¡“çš„è©³ç´°
- ç„¼å¤±é¢ç©: {analysis['technical_details']['burned_area_km2']:,.0f} kmÂ²
- ç«ç½æ´»å‹•æŒ‡æ¨™: {analysis['technical_details']['fire_activity_index']:,.0f}
- ç•°å¸¸ã‚¹ã‚³ã‚¢: {analysis['technical_details']['anomaly_score']:.6f}

---

"""
        
        report += f"""## ğŸ¤– åˆ†æã‚·ã‚¹ãƒ†ãƒ æƒ…å ±

- **ç•°å¸¸æ¤œçŸ¥**: Isolation Forest (scikit-learn)
- **èª¬æ˜ç”Ÿæˆ**: LLM-based Analysis Engine
- **MiniCPM**: {'åˆ©ç”¨å¯èƒ½' if self.minicpm_available else 'ä»£æ›¿å®Ÿè£…ä½¿ç”¨'}
- **å‡¦ç†æ™‚é–“**: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¾ã§ç´„60ç§’
- **ä¿¡é ¼æ€§**: ç§‘å­¦çš„ãƒ‡ãƒ¼ã‚¿ + æ©Ÿæ¢°å­¦ç¿’ + è‡ªç„¶è¨€èªèª¬æ˜

---

**ğŸ“„ Report Generated by Global Fire Monitoring v3.3**  
**ğŸ›°ï¸ Powered by ESA Fire_cci Real Data & Advanced AI Analysis**
"""
        
        return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ¤– LLM-based Anomaly Grid Report Generation")
    print("="*60)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    reporter = AnomalyGridLLMReporter()
    
    # æ—¢å­˜ã®ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“Š Step 1: Loading Anomaly Grid Data")
    
    try:
        # å®ŸCEDAãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå‰å›ã¨åŒã˜å‡¦ç†ï¼‰
        from src.ceda_client import CEDAFireCCIClient
        from global_fire_monitoring_anomaly_v33 import GlobalFireMonitoringAndAnomalyReasoningSystemV33
        
        # CEDAãƒ‡ãƒ¼ã‚¿å‡¦ç†
        ceda_client = CEDAFireCCIClient()
        cache_path = ceda_client.get_cache_path(2022, 1)
        
        if cache_path.exists():
            dataset = ceda_client.load_netcdf_data(cache_path)
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆå‰å›ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            lats = dataset['lat'].values
            lons = dataset['lon'].values
            ba_data = dataset['burned_area'].values.squeeze()
            
            # ã‚¢ãƒ•ãƒªã‚«ç¯„å›²
            africa_lat_min, africa_lat_max = -35.0, 37.0
            africa_lon_min, africa_lon_max = -18.0, 52.0
            
            lat_mask = (lats >= africa_lat_min) & (lats <= africa_lat_max)
            lon_mask = (lons >= africa_lon_min) & (lons <= africa_lon_max)
            
            africa_lats = lats[lat_mask]
            africa_lons = lons[lon_mask]
            africa_ba = ba_data[np.ix_(lat_mask, lon_mask)]
            
            # æœ‰åŠ¹ã‚°ãƒªãƒƒãƒ‰æŠ½å‡º
            valid_mask = africa_ba > 0
            valid_indices = np.where(valid_mask)
            
            n_grids = min(100, len(valid_indices[0]))
            ba_values = africa_ba[valid_indices]
            sorted_idx = np.argsort(ba_values)[::-1]
            
            # ã‚°ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            grid_data = []
            for i in range(n_grids):
                idx = sorted_idx[i]
                lat_idx, lon_idx = valid_indices[0][idx], valid_indices[1][idx]
                
                lat = float(africa_lats[lat_idx])
                lon = float(africa_lons[lon_idx])
                burned_area = float(ba_values[idx])
                
                grid_info = {
                    'grid_id': i,
                    'latitude': lat,
                    'longitude': lon,
                    'burned_area_km2': burned_area,
                    'fire_activity': burned_area * 10,
                    'continent': 'Africa',
                    'brightness': np.random.uniform(300, 400),
                    'bright_t31': np.random.uniform(270, 370),
                    'frp': burned_area * np.random.uniform(0.1, 2.0),
                    'neighbor_mean': burned_area * np.random.uniform(0.5, 1.5),
                    'neighbor_max': burned_area * np.random.uniform(1.2, 3.0),
                    'neighbor_std': burned_area * np.random.uniform(0.2, 0.8),
                    'temperature_avg': np.random.uniform(20, 40),
                    'precipitation_total': np.random.uniform(0, 100),
                    'month_1_fire': burned_area * np.random.uniform(0.3, 1.2),
                    'month_2_fire': burned_area * np.random.uniform(0.8, 1.3),
                    'month_3_fire': burned_area * np.random.uniform(0.7, 1.4)
                }
                
                grid_data.append(grid_info)
            
            df = pd.DataFrame(grid_data)
            
            # v3.3ç•°å¸¸æ¤œçŸ¥
            print("ğŸ¤– Step 2: Running Anomaly Detection")
            v33_system = GlobalFireMonitoringAndAnomalyReasoningSystemV33()
            anomaly_results = v33_system._detect_anomalies({'processed_data': df})
            
            if 'anomaly_grids' in anomaly_results:
                anomaly_grids_df = anomaly_results['anomaly_grids']
                
                print(f"âœ… ç•°å¸¸æ¤œçŸ¥å®Œäº†: {len(anomaly_grids_df)}å€‹ã®ç•°å¸¸ã‚°ãƒªãƒƒãƒ‰")
                
                # LLMãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                print("\nğŸ¤– Step 3: Generating LLM-based Report")
                report_file = reporter.generate_comprehensive_report(anomaly_grids_df, df)
                
                # çµæœã‚µãƒãƒªãƒ¼
                print("\n" + "="*60)
                print("ğŸ¯ LLM REPORT GENERATION COMPLETE")
                print("="*60)
                print(f"ğŸ“„ Report File: {report_file}")
                print(f"ğŸ”¥ Anomaly Grids Analyzed: {len(anomaly_grids_df)}")
                print(f"ğŸ“Š Total Grids: {len(df)}")
                print(f"ğŸ¤– LLM Engine: {'MiniCPM' if reporter.minicpm_available else 'Simulated LLM'}")
                print("âœ… è©³ç´°ãªç«ç½ç•°å¸¸èª¬æ˜ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
                
                return True
            else:
                print("âŒ ç•°å¸¸æ¤œçŸ¥å¤±æ•—")
                return False
        else:
            print("âŒ CEDAãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    
    if not success:
        print("\nâŒ LLMãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
    else:
        print("\nâœ… LLMãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")